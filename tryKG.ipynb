{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66d039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-17 15:53:38,512 - INFO - Connected to Neo4j at bolt://localhost:7687\n",
      "2025-08-17 15:53:38,513 - INFO - Connected to PostgreSQL database research\n",
      "2025-08-17 15:53:38,513 - INFO - ==================================================\n",
      "2025-08-17 15:53:38,513 - INFO - Starting Knowledge Graph Construction (Pre-GNN)\n",
      "2025-08-17 15:53:38,514 - INFO - ==================================================\n",
      "2025-08-17 15:53:40,611 - INFO - Neo4j database cleared\n",
      "2025-08-17 15:53:40,612 - INFO - Creating schema constraints and indexes...\n",
      "2025-08-17 15:53:40,615 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Substation) REQUIRE (e.station_id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_59ea450c FOR (e:Substation) REQUIRE (e.station_id) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (s:Substation) REQUIRE s.station_id IS UNIQUE'\n",
      "2025-08-17 15:53:40,617 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Transformer) REQUIRE (e.transformer_id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_ca1a9091 FOR (e:Transformer) REQUIRE (e.transformer_id) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (t:Transformer) REQUIRE t.transformer_id IS UNIQUE'\n",
      "2025-08-17 15:53:40,620 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:LVCabinet) REQUIRE (e.cabinet_id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_d7aae9c FOR (e:LVCabinet) REQUIRE (e.cabinet_id) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (c:LVCabinet) REQUIRE c.cabinet_id IS UNIQUE'\n",
      "2025-08-17 15:53:40,623 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:CableGroup) REQUIRE (e.group_id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_53e481f2 FOR (e:CableGroup) REQUIRE (e.group_id) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (g:CableGroup) REQUIRE g.group_id IS UNIQUE'\n",
      "2025-08-17 15:53:40,625 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:CableSegment) REQUIRE (e.segment_id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_1aba9ff0 FOR (e:CableSegment) REQUIRE (e.segment_id) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (seg:CableSegment) REQUIRE seg.segment_id IS UNIQUE'\n",
      "2025-08-17 15:53:40,629 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Building) REQUIRE (e.ogc_fid) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_7c5d76a5 FOR (e:Building) REQUIRE (e.ogc_fid) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (b:Building) REQUIRE b.ogc_fid IS UNIQUE'\n",
      "2025-08-17 15:53:40,631 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:ConnectionPoint) REQUIRE (e.point_id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_c1ca41a9 FOR (e:ConnectionPoint) REQUIRE (e.point_id) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (cp:ConnectionPoint) REQUIRE cp.point_id IS UNIQUE'\n",
      "2025-08-17 15:53:40,634 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:TimeSlot) REQUIRE (e.slot_id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_9aaffb77 FOR (e:TimeSlot) REQUIRE (e.slot_id) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (t:TimeSlot) REQUIRE t.slot_id IS UNIQUE'\n",
      "2025-08-17 15:53:40,637 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:EnergyState) REQUIRE (e.state_id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_e74dc457 FOR (e:EnergyState) REQUIRE (e.state_id) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (e:EnergyState) REQUIRE e.state_id IS UNIQUE'\n",
      "2025-08-17 15:53:40,639 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:SolarSystem) REQUIRE (e.system_id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_6438434b FOR (e:SolarSystem) REQUIRE (e.system_id) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (sol:SolarSystem) REQUIRE sol.system_id IS UNIQUE'\n",
      "2025-08-17 15:53:40,643 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:BatterySystem) REQUIRE (e.system_id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_fa52b48a FOR (e:BatterySystem) REQUIRE (e.system_id) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (bat:BatterySystem) REQUIRE bat.system_id IS UNIQUE'\n",
      "2025-08-17 15:53:40,646 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:HeatPumpSystem) REQUIRE (e.system_id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_cfb7b7fe FOR (e:HeatPumpSystem) REQUIRE (e.system_id) IS UNIQUE` already exists.} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (hp:HeatPumpSystem) REQUIRE hp.system_id IS UNIQUE'\n",
      "2025-08-17 15:53:40,649 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX IF NOT EXISTS FOR (e:CableGroup) ON (e.voltage_level)` has no effect.} {description: `RANGE INDEX index_e216af63 FOR (e:CableGroup) ON (e.voltage_level)` already exists.} for query: 'CREATE INDEX IF NOT EXISTS FOR (g:CableGroup) ON (g.voltage_level)'\n",
      "2025-08-17 15:53:40,651 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX IF NOT EXISTS FOR (e:Building) ON (e.lv_group_id)` has no effect.} {description: `RANGE INDEX index_48b97a76 FOR (e:Building) ON (e.lv_group_id)` already exists.} for query: 'CREATE INDEX IF NOT EXISTS FOR (b:Building) ON (b.lv_group_id)'\n",
      "2025-08-17 15:53:40,655 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX IF NOT EXISTS FOR (e:Building) ON (e.building_function)` has no effect.} {description: `RANGE INDEX index_1d4acb42 FOR (e:Building) ON (e.building_function)` already exists.} for query: 'CREATE INDEX IF NOT EXISTS FOR (b:Building) ON (b.building_function)'\n",
      "2025-08-17 15:53:40,658 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX IF NOT EXISTS FOR (e:Building) ON (e.district_name)` has no effect.} {description: `RANGE INDEX index_dddfb1ad FOR (e:Building) ON (e.district_name)` already exists.} for query: 'CREATE INDEX IF NOT EXISTS FOR (b:Building) ON (b.district_name)'\n",
      "2025-08-17 15:53:40,661 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX IF NOT EXISTS FOR (e:Building) ON (e.has_solar)` has no effect.} {description: `RANGE INDEX index_d929426d FOR (e:Building) ON (e.has_solar)` already exists.} for query: 'CREATE INDEX IF NOT EXISTS FOR (b:Building) ON (b.has_solar)'\n",
      "2025-08-17 15:53:40,663 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX IF NOT EXISTS FOR (e:CableSegment) ON (e.group_id)` has no effect.} {description: `RANGE INDEX index_ebf0c2d1 FOR (e:CableSegment) ON (e.group_id)` already exists.} for query: 'CREATE INDEX IF NOT EXISTS FOR (seg:CableSegment) ON (seg.group_id)'\n",
      "2025-08-17 15:53:40,666 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX IF NOT EXISTS FOR (e:ConnectionPoint) ON (e.building_id)` has no effect.} {description: `RANGE INDEX index_da46c9d8 FOR (e:ConnectionPoint) ON (e.building_id)` already exists.} for query: 'CREATE INDEX IF NOT EXISTS FOR (cp:ConnectionPoint) ON (cp.building_id)'\n",
      "2025-08-17 15:53:40,668 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX IF NOT EXISTS FOR (e:TimeSlot) ON (e.timestamp)` has no effect.} {description: `RANGE INDEX index_77e47953 FOR (e:TimeSlot) ON (e.timestamp)` already exists.} for query: 'CREATE INDEX IF NOT EXISTS FOR (t:TimeSlot) ON (t.timestamp)'\n",
      "2025-08-17 15:53:40,671 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX IF NOT EXISTS FOR (e:TimeSlot) ON (e.hour_of_day)` has no effect.} {description: `RANGE INDEX index_402cea7e FOR (e:TimeSlot) ON (e.hour_of_day)` already exists.} for query: 'CREATE INDEX IF NOT EXISTS FOR (t:TimeSlot) ON (t.hour_of_day)'\n",
      "2025-08-17 15:53:40,673 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX IF NOT EXISTS FOR (e:EnergyState) ON (e.building_id)` has no effect.} {description: `RANGE INDEX index_b2716376 FOR (e:EnergyState) ON (e.building_id)` already exists.} for query: 'CREATE INDEX IF NOT EXISTS FOR (e:EnergyState) ON (e.building_id)'\n",
      "2025-08-17 15:53:40,674 - INFO - Schema created successfully\n",
      "2025-08-17 15:53:40,674 - INFO - Loading grid infrastructure from PostgreSQL...\n",
      "2025-08-17 15:53:46,656 - INFO - Created 5031 infrastructure nodes\n",
      "2025-08-17 15:53:46,657 - INFO - Loading building data from PostgreSQL...\n",
      "2025-08-17 15:53:47,011 - INFO - Building features calculated: 1517 buildings processed\n",
      "2025-08-17 15:53:47,012 - INFO -   Solar potential - High: 569, Medium: 417\n",
      "2025-08-17 15:53:47,013 - INFO -   Existing installations - Solar: 60, Battery: 22, Heat Pump: 59\n",
      "2025-08-17 15:54:01,342 - INFO - Created 1517 building nodes with 1517 connection points\n",
      "2025-08-17 15:54:01,345 - INFO - Creating existing asset nodes...\n",
      "2025-08-17 15:54:01,829 - INFO - Created existing assets: 60 solar, 22 battery, 59 heat pumps\n",
      "2025-08-17 15:54:01,830 - INFO - Loading temporal energy data...\n",
      "2025-08-17 15:54:04,931 - INFO - Creating energy states (this may take a moment)...\n",
      "2025-08-17 15:54:40,308 - INFO - Creating temporal relationships...\n",
      "2025-08-17 15:54:40,463 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 2, column: 17, offset: 17} for query: '\\n                MATCH (b:Building), (e:EnergyState {building_id: b.ogc_fid})\\n                CREATE (b)-[:HAS_STATE_AT]->(e)\\n                RETURN count(*) as count\\n            '\n",
      "2025-08-17 15:54:41,129 - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (t))} {position: line: 2, column: 17, offset: 17} for query: '\\n                MATCH (e:EnergyState), (t:TimeSlot {slot_id: e.timeslot_id})\\n                CREATE (e)-[:DURING]->(t)\\n                RETURN count(*) as count\\n            '\n",
      "2025-08-17 15:54:41,129 - INFO - Created 95424 energy states with temporal relationships\n",
      "2025-08-17 15:54:41,130 - INFO - Identifying asset deployment opportunities...\n",
      "2025-08-17 15:54:41,896 - INFO - Identified opportunities: 926 solar, 1463 battery, 1079 heat pumps\n",
      "2025-08-17 15:54:41,896 - INFO - Calculating baseline metrics...\n",
      "2025-08-17 15:54:42,447 - INFO - Baseline: 1517 buildings, 0 kW peak, 0.000 load factor\n",
      "2025-08-17 15:54:42,447 - INFO - Adding metadata...\n",
      "2025-08-17 15:54:42,488 - INFO - Metadata added\n",
      "2025-08-17 15:54:42,488 - INFO - ==================================================\n",
      "2025-08-17 15:54:42,489 - INFO - Pre-GNN Knowledge Graph Construction Complete!\n",
      "2025-08-17 15:54:42,490 - INFO - ==================================================\n",
      "2025-08-17 15:54:42,490 - INFO - Total processing time: 63.97 seconds\n",
      "2025-08-17 15:54:42,491 - INFO - \n",
      "Nodes created:\n",
      "2025-08-17 15:54:42,491 - INFO -   Substation: 2\n",
      "2025-08-17 15:54:42,492 - INFO -   Transformer: 49\n",
      "2025-08-17 15:54:42,492 - INFO -   LVCabinet: 316\n",
      "2025-08-17 15:54:42,493 - INFO -   CableGroup: 209\n",
      "2025-08-17 15:54:42,493 - INFO -   CableSegment: 4,455\n",
      "2025-08-17 15:54:42,494 - INFO -   Building: 1,517\n",
      "2025-08-17 15:54:42,494 - INFO -   ConnectionPoint: 1,517\n",
      "2025-08-17 15:54:42,495 - INFO -   ExistingSolar: 60\n",
      "2025-08-17 15:54:42,495 - INFO -   ExistingBattery: 22\n",
      "2025-08-17 15:54:42,496 - INFO -   ExistingHeatPump: 59\n",
      "2025-08-17 15:54:42,496 - INFO -   TimeSlot: 672\n",
      "2025-08-17 15:54:42,497 - INFO -   EnergyState: 95,424\n",
      "2025-08-17 15:54:42,497 - INFO -   SolarPotential: 926\n",
      "2025-08-17 15:54:42,497 - INFO -   BatteryPotential: 1,463\n",
      "2025-08-17 15:54:42,498 - INFO -   HeatPumpPotential: 1,079\n",
      "2025-08-17 15:54:42,499 - INFO -   TOTAL: 107,770\n",
      "2025-08-17 15:54:42,499 - INFO - \n",
      "Relationships created:\n",
      "2025-08-17 15:54:42,500 - INFO -   FEEDS_FROM: 136\n",
      "2025-08-17 15:54:42,500 - INFO -   CONNECTED_TO: 1,517\n",
      "2025-08-17 15:54:42,501 - INFO -   HAS_CONNECTION_POINT: 1,517\n",
      "2025-08-17 15:54:42,502 - INFO -   ON_SEGMENT: 1,517\n",
      "2025-08-17 15:54:42,503 - INFO -   NEAR_MV: 39\n",
      "2025-08-17 15:54:42,503 - INFO -   HAS_INSTALLED: 141\n",
      "2025-08-17 15:54:42,504 - INFO -   HAS_STATE_AT: 0\n",
      "2025-08-17 15:54:42,504 - INFO -   DURING: 95,424\n",
      "2025-08-17 15:54:42,505 - INFO -   TOTAL: 100,291\n",
      "2025-08-17 15:54:42,505 - INFO - \n",
      "⚠️ Note: Complementarity analysis and clustering will be added after GNN processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Grid Infrastructure Summary:\n",
      "==================================================\n",
      "lv_cabinet: 316 components\n",
      "cable_group: 209 components\n",
      "transformer: 49 components\n",
      "substation: 2 components\n",
      "\n",
      "==================================================\n",
      "Top 10 LV Groups by Building Count:\n",
      "==================================================\n",
      "No metrics yet\n",
      "No metrics yet\n",
      "No metrics yet\n",
      "No metrics yet\n",
      "No metrics yet\n",
      "No metrics yet\n",
      "No metrics yet\n",
      "No metrics yet\n",
      "No metrics yet\n",
      "No metrics yet\n",
      "\n",
      "==================================================\n",
      "Building Connection Quality:\n",
      "==================================================\n",
      "BY_DISTANCE: 1440 buildings, Avg distance: 13.9m\n",
      "ENDED: 67 buildings, Avg distance: 13.8m\n",
      "CROSSED: 9 buildings, Avg distance: 15.9m\n",
      "TOO_FAR: 1 buildings, Avg distance: 215.5m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-17 15:54:42,760 - INFO - Database connections closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Deployment Opportunities Identified:\n",
      "==================================================\n",
      "Solar: 926 buildings\n",
      "Battery: 1463 buildings\n",
      "Heat Pump: 1079 buildings\n",
      "\n",
      "✅ Pre-GNN Knowledge Graph construction complete!\n",
      "Ready for GNN processing to discover complementarity and optimal clustering\n",
      "You can explore the graph in Neo4j Browser at http://localhost:7474\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Knowledge Graph Builder for Energy District Analysis - PRE-GNN VERSION\n",
    "Updated to use actual PostgreSQL database schema with rich grid infrastructure\n",
    "Creates the foundational KG with raw data, infrastructure, and potential\n",
    "Complementarity and clustering will be added AFTER GNN analysis\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neo4j import GraphDatabase\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from decimal import Decimal\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EnergyKnowledgeGraphBuilder:\n",
    "    \"\"\"Build Knowledge Graph from energy district data - Pre-GNN version\"\"\"\n",
    "    \n",
    "    def __init__(self, neo4j_uri: str, neo4j_user: str, neo4j_password: str,\n",
    "                 pg_host: str, pg_database: str, pg_user: str, pg_password: str):\n",
    "        \"\"\"Initialize Neo4j and PostgreSQL connections\"\"\"\n",
    "        # Neo4j connection\n",
    "        self.driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))\n",
    "        \n",
    "        # PostgreSQL connection\n",
    "        self.pg_conn = psycopg2.connect(\n",
    "            host=pg_host,\n",
    "            database=pg_database,\n",
    "            user=pg_user,\n",
    "            password=pg_password,\n",
    "            port=5433\n",
    "        )\n",
    "        \n",
    "        self.stats = {\n",
    "            'nodes_created': {},\n",
    "            'relationships_created': {},\n",
    "            'processing_time': {}\n",
    "        }\n",
    "        logger.info(f\"Connected to Neo4j at {neo4j_uri}\")\n",
    "        logger.info(f\"Connected to PostgreSQL database {pg_database}\")\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close database connections\"\"\"\n",
    "        self.driver.close()\n",
    "        self.pg_conn.close()\n",
    "        logger.info(\"Database connections closed\")\n",
    "    \n",
    "    def clear_database(self):\n",
    "        \"\"\"Clear all nodes and relationships\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "            logger.info(\"Neo4j database cleared\")\n",
    "    \n",
    "    def convert_decimals(self, record):\n",
    "        \"\"\"Convert Decimal types to float for Neo4j compatibility\"\"\"\n",
    "        if isinstance(record, dict):\n",
    "            return {k: float(v) if isinstance(v, Decimal) else v for k, v in record.items()}\n",
    "        elif isinstance(record, list):\n",
    "            return [self.convert_decimals(item) for item in record]\n",
    "        else:\n",
    "            return float(record) if isinstance(record, Decimal) else record\n",
    "\n",
    "    # ============================================\n",
    "    # STEP 1: SCHEMA SETUP\n",
    "    # ============================================\n",
    "    \n",
    "    def create_schema(self):\n",
    "        \"\"\"Create constraints and indexes for pre-GNN KG\"\"\"\n",
    "        logger.info(\"Creating schema constraints and indexes...\")\n",
    "        \n",
    "        constraints = [\n",
    "            # Infrastructure\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (s:Substation) REQUIRE s.station_id IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (t:Transformer) REQUIRE t.transformer_id IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (c:LVCabinet) REQUIRE c.cabinet_id IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (g:CableGroup) REQUIRE g.group_id IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (seg:CableSegment) REQUIRE seg.segment_id IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (b:Building) REQUIRE b.ogc_fid IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (cp:ConnectionPoint) REQUIRE cp.point_id IS UNIQUE\",\n",
    "            \n",
    "            # Temporal\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (t:TimeSlot) REQUIRE t.slot_id IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (e:EnergyState) REQUIRE e.state_id IS UNIQUE\",\n",
    "            \n",
    "            # Assets\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (sol:SolarSystem) REQUIRE sol.system_id IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (bat:BatterySystem) REQUIRE bat.system_id IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (hp:HeatPumpSystem) REQUIRE hp.system_id IS UNIQUE\",\n",
    "        ]\n",
    "        \n",
    "        indexes = [\n",
    "            # Performance indexes\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (g:CableGroup) ON (g.voltage_level)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (b:Building) ON (b.lv_group_id)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (b:Building) ON (b.building_function)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (b:Building) ON (b.district_name)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (b:Building) ON (b.has_solar)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (seg:CableSegment) ON (seg.group_id)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (cp:ConnectionPoint) ON (cp.building_id)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (t:TimeSlot) ON (t.timestamp)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (t:TimeSlot) ON (t.hour_of_day)\",\n",
    "            \"CREATE INDEX IF NOT EXISTS FOR (e:EnergyState) ON (e.building_id)\",\n",
    "        ]\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            for constraint in constraints:\n",
    "                session.run(constraint)\n",
    "            for index in indexes:\n",
    "                session.run(index)\n",
    "        \n",
    "        logger.info(\"Schema created successfully\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 2: LOAD GRID INFRASTRUCTURE\n",
    "    # ============================================\n",
    "    \n",
    "    def load_grid_infrastructure(self):\n",
    "        \"\"\"Load complete grid topology from PostgreSQL\"\"\"\n",
    "        logger.info(\"Loading grid infrastructure from PostgreSQL...\")\n",
    "        \n",
    "        with self.pg_conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "            \n",
    "            # Load Substations\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    fid as station_id,\n",
    "                    ST_X(clipped_geom) as x,\n",
    "                    ST_Y(clipped_geom) as y,\n",
    "                    ST_AsText(clipped_geom) as geom_wkt\n",
    "                FROM amin_grid.tlip_onderstations\n",
    "                WHERE clipped_geom IS NOT NULL\n",
    "            \"\"\")\n",
    "            substations = [self.convert_decimals(row) for row in cursor.fetchall()]\n",
    "            \n",
    "            # Load Transformers (MV installations)\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    fid as transformer_id,\n",
    "                    ST_X(clipped_geom) as x,\n",
    "                    ST_Y(clipped_geom) as y,\n",
    "                    ST_AsText(clipped_geom) as geom_wkt\n",
    "                FROM amin_grid.tlip_middenspanningsinstallaties\n",
    "                WHERE clipped_geom IS NOT NULL\n",
    "            \"\"\")\n",
    "            transformers = [self.convert_decimals(row) for row in cursor.fetchall()]\n",
    "            \n",
    "            # Load LV Cabinets\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    fid as cabinet_id,\n",
    "                    ST_X(clipped_geom) as x,\n",
    "                    ST_Y(clipped_geom) as y,\n",
    "                    ST_AsText(clipped_geom) as geom_wkt\n",
    "                FROM amin_grid.tlip_laagspanningsverdeelkasten\n",
    "                WHERE clipped_geom IS NOT NULL\n",
    "            \"\"\")\n",
    "            lv_cabinets = [self.convert_decimals(row) for row in cursor.fetchall()]\n",
    "            \n",
    "            # Load Cable Groups (connected components)\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    group_id,\n",
    "                    voltage_level,\n",
    "                    segment_count,\n",
    "                    total_length_m,\n",
    "                    ST_X(centroid) as x,\n",
    "                    ST_Y(centroid) as y,\n",
    "                    ST_AsText(bbox) as bbox_wkt\n",
    "                FROM amin_grid.tlip_connected_groups\n",
    "            \"\"\")\n",
    "            cable_groups = [self.convert_decimals(row) for row in cursor.fetchall()]\n",
    "            \n",
    "            # Load Cable Segments\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    segment_id,\n",
    "                    original_fid,\n",
    "                    voltage_level,\n",
    "                    group_id,\n",
    "                    length_m,\n",
    "                    ST_X(start_point) as start_x,\n",
    "                    ST_Y(start_point) as start_y,\n",
    "                    ST_X(end_point) as end_x,\n",
    "                    ST_Y(end_point) as end_y\n",
    "                FROM amin_grid.tlip_cable_segments\n",
    "                WHERE group_id IS NOT NULL\n",
    "            \"\"\")\n",
    "            cable_segments = [self.convert_decimals(row) for row in cursor.fetchall()]\n",
    "            \n",
    "            # Load hierarchy relationships\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    child_group_id,\n",
    "                    child_voltage,\n",
    "                    parent_group_id,\n",
    "                    parent_voltage,\n",
    "                    connection_via,\n",
    "                    via_station_fid,\n",
    "                    confidence_score\n",
    "                FROM amin_grid.tlip_group_hierarchy\n",
    "            \"\"\")\n",
    "            hierarchy = [self.convert_decimals(row) for row in cursor.fetchall()]\n",
    "            \n",
    "            # Load group-station connections\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    group_id,\n",
    "                    voltage_level,\n",
    "                    station_type,\n",
    "                    station_fid,\n",
    "                    connection_type,\n",
    "                    distance_m,\n",
    "                    confidence_score\n",
    "                FROM amin_grid.tlip_group_stations\n",
    "            \"\"\")\n",
    "            group_stations = [self.convert_decimals(row) for row in cursor.fetchall()]\n",
    "        \n",
    "        # Create nodes in Neo4j\n",
    "        with self.driver.session() as session:\n",
    "            # Create Substations\n",
    "            for substation in substations:\n",
    "                session.run(\"\"\"\n",
    "                    CREATE (s:GridComponent:Substation {\n",
    "                        station_id: $station_id,\n",
    "                        x: $x,\n",
    "                        y: $y,\n",
    "                        voltage_level: 'HV',\n",
    "                        component_type: 'substation',\n",
    "                        geom_wkt: $geom_wkt\n",
    "                    })\n",
    "                \"\"\", **substation)\n",
    "            self.stats['nodes_created']['Substation'] = len(substations)\n",
    "            \n",
    "            # Create Transformers\n",
    "            for transformer in transformers:\n",
    "                session.run(\"\"\"\n",
    "                    CREATE (t:GridComponent:Transformer {\n",
    "                        transformer_id: $transformer_id,\n",
    "                        x: $x,\n",
    "                        y: $y,\n",
    "                        voltage_level: 'MV',\n",
    "                        component_type: 'transformer',\n",
    "                        geom_wkt: $geom_wkt\n",
    "                    })\n",
    "                \"\"\", **transformer)\n",
    "            self.stats['nodes_created']['Transformer'] = len(transformers)\n",
    "            \n",
    "            # Create LV Cabinets\n",
    "            for cabinet in lv_cabinets:\n",
    "                session.run(\"\"\"\n",
    "                    CREATE (c:GridComponent:LVCabinet {\n",
    "                        cabinet_id: $cabinet_id,\n",
    "                        x: $x,\n",
    "                        y: $y,\n",
    "                        voltage_level: 'LV',\n",
    "                        component_type: 'lv_cabinet',\n",
    "                        geom_wkt: $geom_wkt\n",
    "                    })\n",
    "                \"\"\", **cabinet)\n",
    "            self.stats['nodes_created']['LVCabinet'] = len(lv_cabinets)\n",
    "            \n",
    "            # Create Cable Groups\n",
    "            for group in cable_groups:\n",
    "                session.run(\"\"\"\n",
    "                    CREATE (g:GridComponent:CableGroup {\n",
    "                        group_id: $group_id,\n",
    "                        voltage_level: $voltage_level,\n",
    "                        segment_count: $segment_count,\n",
    "                        total_length_m: $total_length_m,\n",
    "                        x: $x,\n",
    "                        y: $y,\n",
    "                        bbox_wkt: $bbox_wkt,\n",
    "                        component_type: 'cable_group'\n",
    "                    })\n",
    "                \"\"\", **group)\n",
    "            self.stats['nodes_created']['CableGroup'] = len(cable_groups)\n",
    "            \n",
    "            # Create Cable Segments\n",
    "            segment_batch = []\n",
    "            for segment in cable_segments:\n",
    "                segment_batch.append({\n",
    "                    'segment_id': segment['segment_id'],\n",
    "                    'original_fid': segment['original_fid'],\n",
    "                    'voltage_level': segment['voltage_level'],\n",
    "                    'group_id': segment['group_id'],\n",
    "                    'length_m': float(segment['length_m']),\n",
    "                    'start_x': float(segment['start_x']),\n",
    "                    'start_y': float(segment['start_y']),\n",
    "                    'end_x': float(segment['end_x']),\n",
    "                    'end_y': float(segment['end_y'])\n",
    "                })\n",
    "                \n",
    "                if len(segment_batch) >= 1000:\n",
    "                    session.run(\"\"\"\n",
    "                        UNWIND $segments as seg\n",
    "                        CREATE (s:CableSegment {\n",
    "                            segment_id: seg.segment_id,\n",
    "                            original_fid: seg.original_fid,\n",
    "                            voltage_level: seg.voltage_level,\n",
    "                            group_id: seg.group_id,\n",
    "                            length_m: seg.length_m,\n",
    "                            start_x: seg.start_x,\n",
    "                            start_y: seg.start_y,\n",
    "                            end_x: seg.end_x,\n",
    "                            end_y: seg.end_y\n",
    "                        })\n",
    "                    \"\"\", segments=segment_batch)\n",
    "                    segment_batch = []\n",
    "            \n",
    "            if segment_batch:\n",
    "                session.run(\"\"\"\n",
    "                    UNWIND $segments as seg\n",
    "                    CREATE (s:CableSegment {\n",
    "                        segment_id: seg.segment_id,\n",
    "                        original_fid: seg.original_fid,\n",
    "                        voltage_level: seg.voltage_level,\n",
    "                        group_id: seg.group_id,\n",
    "                        length_m: seg.length_m,\n",
    "                        start_x: seg.start_x,\n",
    "                        start_y: seg.start_y,\n",
    "                        end_x: seg.end_x,\n",
    "                        end_y: seg.end_y\n",
    "                    })\n",
    "                \"\"\", segments=segment_batch)\n",
    "            \n",
    "            self.stats['nodes_created']['CableSegment'] = len(cable_segments)\n",
    "            \n",
    "            # Create hierarchy relationships\n",
    "            for rel in hierarchy:\n",
    "                session.run(\"\"\"\n",
    "                    MATCH (child:CableGroup {group_id: $child_group_id})\n",
    "                    MATCH (parent:CableGroup {group_id: $parent_group_id})\n",
    "                    CREATE (child)-[:FEEDS_FROM {\n",
    "                        connection_via: $connection_via,\n",
    "                        via_station_fid: $via_station_fid,\n",
    "                        confidence_score: $confidence_score\n",
    "                    }]->(parent)\n",
    "                \"\"\", **rel)\n",
    "            self.stats['relationships_created']['FEEDS_FROM'] = len(hierarchy)\n",
    "            \n",
    "            # Create group-station relationships\n",
    "            for conn in group_stations:\n",
    "                if conn['station_type'] == 'TRANSFORMER':\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (g:CableGroup {group_id: $group_id})\n",
    "                        MATCH (t:Transformer {transformer_id: $station_fid})\n",
    "                        CREATE (g)-[:CONNECTS_TO {\n",
    "                            connection_type: $connection_type,\n",
    "                            distance_m: $distance_m,\n",
    "                            confidence_score: $confidence_score\n",
    "                        }]->(t)\n",
    "                    \"\"\", **conn)\n",
    "                elif conn['station_type'] == 'SUBSTATION':\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (g:CableGroup {group_id: $group_id})\n",
    "                        MATCH (s:Substation {station_id: $station_fid})\n",
    "                        CREATE (g)-[:CONNECTS_TO {\n",
    "                            connection_type: $connection_type,\n",
    "                            distance_m: $distance_m,\n",
    "                            confidence_score: $confidence_score\n",
    "                        }]->(s)\n",
    "                    \"\"\", **conn)\n",
    "                elif conn['station_type'] == 'LV_CABINET':\n",
    "                    session.run(\"\"\"\n",
    "                        MATCH (g:CableGroup {group_id: $group_id})\n",
    "                        MATCH (c:LVCabinet {cabinet_id: $station_fid})\n",
    "                        CREATE (g)-[:CONNECTS_TO {\n",
    "                            connection_type: $connection_type,\n",
    "                            distance_m: $distance_m,\n",
    "                            confidence_score: $confidence_score\n",
    "                        }]->(c)\n",
    "                    \"\"\", **conn)\n",
    "            \n",
    "            # Create segment to group relationships\n",
    "            session.run(\"\"\"\n",
    "                MATCH (s:CableSegment)\n",
    "                MATCH (g:CableGroup {group_id: s.group_id})\n",
    "                CREATE (s)-[:PART_OF]->(g)\n",
    "            \"\"\")\n",
    "            \n",
    "        logger.info(f\"Created {sum(self.stats['nodes_created'].values())} infrastructure nodes\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 3: LOAD AND ENHANCE BUILDINGS\n",
    "    # ============================================\n",
    "    \n",
    "    def load_buildings(self):\n",
    "        \"\"\"Load buildings with all connection metadata\"\"\"\n",
    "        logger.info(\"Loading building data from PostgreSQL...\")\n",
    "        \n",
    "        with self.pg_conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "            # Load buildings with connection data\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    b.ogc_fid,\n",
    "                    b.x,\n",
    "                    b.y,\n",
    "                    b.building_function,\n",
    "                    b.residential_type,\n",
    "                    b.non_residential_type,\n",
    "                    b.area,\n",
    "                    b.height,\n",
    "                    b.age_range,\n",
    "                    b.building_orientation_cardinal,\n",
    "                    b.meestvoorkomendelabel as energy_label,\n",
    "                    b.woningtype as housing_type,\n",
    "                    b.wijknaam as district_name,\n",
    "                    b.buurtnaam as neighborhood_name,\n",
    "                    b.bouwjaar as building_year,\n",
    "                    b.b3_opp_dak_plat as flat_roof_area,\n",
    "                    b.b3_opp_dak_schuin as sloped_roof_area,\n",
    "                    -- Connection data\n",
    "                    bc.connected_group_id as lv_group_id,\n",
    "                    bc.connected_segment_id,\n",
    "                    bc.connection_distance_m,\n",
    "                    bc.connection_type,\n",
    "                    bc.is_mv_capable,\n",
    "                    bc.has_mv_nearby,\n",
    "                    bc.nearest_mv_distance_m,\n",
    "                    bc.is_problematic,\n",
    "                    bc.connection_reason,\n",
    "                    -- Energy indicators\n",
    "                    b.ndvi_mean_100m,\n",
    "                    b.ntl_mean_500m,\n",
    "                    b.ndwi_mean_250m\n",
    "                FROM amin.buildings_1_deducted b\n",
    "                LEFT JOIN amin_grid.tlip_building_connections bc\n",
    "                    ON b.ogc_fid = bc.building_id\n",
    "                WHERE b.area > 10 \n",
    "                    AND b.pand_geom IS NOT NULL\n",
    "                    AND bc.connected_group_id IS NOT NULL\n",
    "            \"\"\")\n",
    "            buildings = [self.convert_decimals(row) for row in cursor.fetchall()]\n",
    "            \n",
    "            # Load connection points\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    connection_point_id as point_id,\n",
    "                    building_id,\n",
    "                    segment_id,\n",
    "                    group_id,\n",
    "                    connection_type,\n",
    "                    ST_X(point_on_line) as point_x,\n",
    "                    ST_Y(point_on_line) as point_y,\n",
    "                    distance_along_segment,\n",
    "                    segment_fraction,\n",
    "                    connection_distance_m,\n",
    "                    is_direct_connection\n",
    "                FROM amin_grid.tlip_building_connection_points\n",
    "            \"\"\")\n",
    "            connection_points = [self.convert_decimals(row) for row in cursor.fetchall()]\n",
    "        \n",
    "        # Process buildings and add derived features\n",
    "        buildings_df = pd.DataFrame(buildings)\n",
    "        buildings_df = self._calculate_building_features(buildings_df)\n",
    "        \n",
    "        # Create nodes in Neo4j\n",
    "        with self.driver.session() as session:\n",
    "            # Create building nodes with all features\n",
    "            for _, building in buildings_df.iterrows():\n",
    "                session.run(\"\"\"\n",
    "                    CREATE (b:Building {\n",
    "                        ogc_fid: $ogc_fid,\n",
    "                        x: $x,\n",
    "                        y: $y,\n",
    "                        building_function: $function,\n",
    "                        residential_type: $res_type,\n",
    "                        non_residential_type: $non_res_type,\n",
    "                        area: $area,\n",
    "                        height: $height,\n",
    "                        age_range: $age,\n",
    "                        building_year: $year,\n",
    "                        building_orientation_cardinal: $orientation,\n",
    "                        district_name: $district,\n",
    "                        neighborhood_name: $neighborhood,\n",
    "                        housing_type: $housing_type,\n",
    "                        \n",
    "                        // Roof data\n",
    "                        flat_roof_area: $flat_roof,\n",
    "                        sloped_roof_area: $sloped_roof,\n",
    "                        suitable_roof_area: $suitable_roof,\n",
    "                        \n",
    "                        // Connection data\n",
    "                        lv_group_id: $lv_group,\n",
    "                        connection_segment_id: $segment_id,\n",
    "                        connection_type: $conn_type,\n",
    "                        connection_distance_m: $conn_distance,\n",
    "                        is_mv_capable: $mv_capable,\n",
    "                        has_mv_nearby: $mv_nearby,\n",
    "                        nearest_mv_distance_m: $mv_distance,\n",
    "                        is_problematic: $problematic,\n",
    "                        connection_reason: $conn_reason,\n",
    "                        \n",
    "                        // Energy features\n",
    "                        energy_label: $energy_label,\n",
    "                        energy_label_simple: $energy_label_simple,\n",
    "                        insulation_quality: $insulation,\n",
    "                        solar_potential: $solar_pot,\n",
    "                        solar_capacity_kwp: $solar_kwp,\n",
    "                        battery_readiness: $battery_ready,\n",
    "                        electrification_feasibility: $elec_feasible,\n",
    "                        expected_cop: $cop,\n",
    "                        \n",
    "                        // Environmental indicators\n",
    "                        vegetation_index: $ndvi,\n",
    "                        nighttime_lights: $ntl,\n",
    "                        water_index: $ndwi,\n",
    "                        \n",
    "                        // Current assets (initially false/none)\n",
    "                        has_solar: $has_solar,\n",
    "                        has_battery: $has_battery,\n",
    "                        has_heat_pump: $has_hp,\n",
    "                        heating_system: $heating\n",
    "                    })\n",
    "                \"\"\",\n",
    "                ogc_fid=int(building['ogc_fid']),\n",
    "                x=float(building['x']),\n",
    "                y=float(building['y']),\n",
    "                function=building['building_function'],\n",
    "                res_type=building['residential_type'] if pd.notna(building['residential_type']) else 'None',\n",
    "                non_res_type=building['non_residential_type'] if pd.notna(building['non_residential_type']) else 'None',\n",
    "                area=float(building['area']),\n",
    "                height=float(building['height']) if pd.notna(building['height']) else 3.0,\n",
    "                age=building['age_range'] if pd.notna(building['age_range']) else 'Unknown',\n",
    "                year=int(building['building_year']) if pd.notna(building['building_year']) else 0,\n",
    "                orientation=building['building_orientation_cardinal'] if pd.notna(building['building_orientation_cardinal']) else 'Unknown',\n",
    "                district=building['district_name'] if pd.notna(building['district_name']) else 'Unknown',\n",
    "                neighborhood=building['neighborhood_name'] if pd.notna(building['neighborhood_name']) else 'Unknown',\n",
    "                housing_type=building['housing_type'] if pd.notna(building['housing_type']) else 'Unknown',\n",
    "                flat_roof=float(building['flat_roof_area']) if pd.notna(building['flat_roof_area']) else 0.0,\n",
    "                sloped_roof=float(building['sloped_roof_area']) if pd.notna(building['sloped_roof_area']) else 0.0,\n",
    "                suitable_roof=float(building['suitable_roof_area']),\n",
    "                lv_group=building['lv_group_id'],\n",
    "                segment_id=int(building['connected_segment_id']) if pd.notna(building['connected_segment_id']) else 0,\n",
    "                conn_type=building['connection_type'],\n",
    "                conn_distance=float(building['connection_distance_m']),\n",
    "                mv_capable=bool(building['is_mv_capable']),\n",
    "                mv_nearby=bool(building['has_mv_nearby']),\n",
    "                mv_distance=float(building['nearest_mv_distance_m']) if pd.notna(building['nearest_mv_distance_m']) else 999.0,\n",
    "                problematic=bool(building['is_problematic']),\n",
    "                conn_reason=building['connection_reason'] if pd.notna(building['connection_reason']) else '',\n",
    "                energy_label=building['energy_label'] if pd.notna(building['energy_label']) else 'Unknown',\n",
    "                energy_label_simple=building['energy_label_simple'],\n",
    "                insulation=building['insulation_quality'],\n",
    "                solar_pot=building['solar_potential'],\n",
    "                solar_kwp=float(building['solar_capacity_kwp']),\n",
    "                battery_ready=building['battery_readiness'],\n",
    "                elec_feasible=building['electrification_feasibility'],\n",
    "                cop=float(building['expected_cop']),\n",
    "                ndvi=float(building['ndvi_mean_100m']) if pd.notna(building['ndvi_mean_100m']) else 0.0,\n",
    "                ntl=float(building['ntl_mean_500m']) if pd.notna(building['ntl_mean_500m']) else 0.0,\n",
    "                ndwi=float(building['ndwi_mean_250m']) if pd.notna(building['ndwi_mean_250m']) else 0.0,\n",
    "                has_solar=bool(building['has_solar']),\n",
    "                has_battery=bool(building['has_battery']),\n",
    "                has_hp=bool(building['has_heat_pump']),\n",
    "                heating=building['heating_system']\n",
    "                )\n",
    "            \n",
    "            self.stats['nodes_created']['Building'] = len(buildings_df)\n",
    "            \n",
    "            # Create Connection Point nodes\n",
    "            for point in connection_points:\n",
    "                session.run(\"\"\"\n",
    "                    CREATE (cp:ConnectionPoint {\n",
    "                        point_id: $point_id,\n",
    "                        building_id: $building_id,\n",
    "                        segment_id: $segment_id,\n",
    "                        group_id: $group_id,\n",
    "                        connection_type: $conn_type,\n",
    "                        x: $x,\n",
    "                        y: $y,\n",
    "                        distance_along_segment: $dist_along,\n",
    "                        segment_fraction: $fraction,\n",
    "                        connection_distance_m: $conn_dist,\n",
    "                        is_direct: $is_direct\n",
    "                    })\n",
    "                \"\"\",\n",
    "                point_id=int(point['point_id']),\n",
    "                building_id=int(point['building_id']),\n",
    "                segment_id=int(point['segment_id']),\n",
    "                group_id=point['group_id'],\n",
    "                conn_type=point['connection_type'],\n",
    "                x=float(point['point_x']),\n",
    "                y=float(point['point_y']),\n",
    "                dist_along=float(point['distance_along_segment']),\n",
    "                fraction=float(point['segment_fraction']),\n",
    "                conn_dist=float(point['connection_distance_m']),\n",
    "                is_direct=bool(point['is_direct_connection'])\n",
    "                )\n",
    "            \n",
    "            self.stats['nodes_created']['ConnectionPoint'] = len(connection_points)\n",
    "            \n",
    "            # Create relationships\n",
    "            # Building -> LV Cable Group\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                MATCH (g:CableGroup {group_id: b.lv_group_id})\n",
    "                CREATE (b)-[:CONNECTED_TO {\n",
    "                    connection_type: b.connection_type,\n",
    "                    distance_m: b.connection_distance_m,\n",
    "                    is_problematic: b.is_problematic\n",
    "                }]->(g)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            self.stats['relationships_created']['CONNECTED_TO'] = result.single()['count']\n",
    "            \n",
    "            # Building -> Connection Point\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                MATCH (cp:ConnectionPoint {building_id: b.ogc_fid})\n",
    "                CREATE (b)-[:HAS_CONNECTION_POINT]->(cp)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            self.stats['relationships_created']['HAS_CONNECTION_POINT'] = result.single()['count']\n",
    "            \n",
    "            # Connection Point -> Cable Segment\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (cp:ConnectionPoint)\n",
    "                MATCH (s:CableSegment {segment_id: cp.segment_id})\n",
    "                CREATE (cp)-[:ON_SEGMENT {\n",
    "                    fraction: cp.segment_fraction,\n",
    "                    distance_along: cp.distance_along_segment\n",
    "                }]->(s)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            self.stats['relationships_created']['ON_SEGMENT'] = result.single()['count']\n",
    "            \n",
    "            # Building NEAR_MV for MV-capable buildings\n",
    "            # Building NEAR_MV for MV-capable buildings\n",
    "            # Building NEAR_MV for MV-capable buildings\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building {is_mv_capable: true, has_mv_nearby: true})\n",
    "                MATCH (g:CableGroup {voltage_level: 'MV'})\n",
    "                WHERE point.distance(point({x: b.x, y: b.y}), point({x: g.x, y: g.y})) < 200\n",
    "                WITH b, g, point.distance(point({x: b.x, y: b.y}), point({x: g.x, y: g.y})) as dist\n",
    "                ORDER BY dist\n",
    "                WITH b, head(collect(g)) as nearest_mv, min(dist) as min_dist\n",
    "                CREATE (b)-[:NEAR_MV {distance_m: min_dist}]->(nearest_mv)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            self.stats['relationships_created']['NEAR_MV'] = result.single()['count']\n",
    "            \n",
    "        logger.info(f\"Created {len(buildings_df)} building nodes with {len(connection_points)} connection points\")\n",
    "    \n",
    "    def _calculate_building_features(self, buildings: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate derived building features\"\"\"\n",
    "        \n",
    "        # Simplify energy label\n",
    "        def simplify_label(label):\n",
    "            if pd.isna(label):\n",
    "                return 'Unknown'\n",
    "            if label in ['A', 'A+', 'A++', 'A+++', 'A++++']:\n",
    "                return 'A'\n",
    "            elif label in ['B', 'C', 'D', 'E', 'F', 'G']:\n",
    "                return label\n",
    "            else:\n",
    "                return 'Unknown'\n",
    "        \n",
    "        buildings['energy_label_simple'] = buildings['energy_label'].apply(simplify_label)\n",
    "        \n",
    "        # If no energy label, estimate from age\n",
    "        def estimate_label(row):\n",
    "            if row['energy_label_simple'] != 'Unknown':\n",
    "                return row['energy_label_simple']\n",
    "            \n",
    "            age_labels = {\n",
    "                '< 1945': 'F',\n",
    "                '1945-1975': 'E', \n",
    "                '1975-1990': 'D',\n",
    "                '1990-2005': 'C',\n",
    "                '2005-2015': 'B',\n",
    "                '> 2015': 'A'\n",
    "            }\n",
    "            return age_labels.get(row['age_range'], 'D')\n",
    "        \n",
    "        buildings['energy_label_simple'] = buildings.apply(estimate_label, axis=1)\n",
    "        \n",
    "        # Insulation quality\n",
    "        label_insulation = {\n",
    "            'A': 'excellent', 'B': 'good', 'C': 'fair',\n",
    "            'D': 'fair', 'E': 'poor', 'F': 'poor', \n",
    "            'G': 'very_poor', 'Unknown': 'unknown'\n",
    "        }\n",
    "        buildings['insulation_quality'] = buildings['energy_label_simple'].map(label_insulation)\n",
    "        \n",
    "        # Calculate suitable roof area\n",
    "        buildings['suitable_roof_area'] = buildings['flat_roof_area'].fillna(0) + \\\n",
    "            buildings.apply(lambda x: x['sloped_roof_area'] * 0.6 \n",
    "                          if x['building_orientation_cardinal'] in ['S', 'SE', 'SW'] \n",
    "                          else x['sloped_roof_area'] * 0.3 if pd.notna(x['sloped_roof_area']) else 0, axis=1)\n",
    "        \n",
    "        # Solar potential\n",
    "        def get_solar_potential(row):\n",
    "            if row['suitable_roof_area'] > 100:\n",
    "                return 'high'\n",
    "            elif row['suitable_roof_area'] > 50:\n",
    "                return 'medium'\n",
    "            elif row['suitable_roof_area'] > 25:\n",
    "                return 'low'\n",
    "            else:\n",
    "                return 'none'\n",
    "        \n",
    "        buildings['solar_potential'] = buildings.apply(get_solar_potential, axis=1)\n",
    "        \n",
    "        # Solar capacity potential\n",
    "        buildings['solar_capacity_kwp'] = buildings['suitable_roof_area'] * 0.15 * 0.7\n",
    "        \n",
    "        # Battery readiness (based on solar potential and building type)\n",
    "        def get_battery_readiness(row):\n",
    "            if row['solar_potential'] in ['high', 'medium']:\n",
    "                return 'ready'\n",
    "            elif row['is_mv_capable'] or row['building_function'] == 'non_residential':\n",
    "                return 'conditional'\n",
    "            else:\n",
    "                return 'not_ready'\n",
    "        \n",
    "        buildings['battery_readiness'] = buildings.apply(get_battery_readiness, axis=1)\n",
    "        \n",
    "        # Electrification feasibility\n",
    "        def get_electrification_feasibility(row):\n",
    "            if row['energy_label_simple'] in ['F', 'G']:\n",
    "                return 'upgrade_needed'\n",
    "            elif row['energy_label_simple'] in ['D', 'E']:\n",
    "                return 'conditional'\n",
    "            else:\n",
    "                return 'immediate'\n",
    "        \n",
    "        buildings['electrification_feasibility'] = buildings.apply(get_electrification_feasibility, axis=1)\n",
    "        \n",
    "        # Expected COP for heat pumps\n",
    "        cop_by_label = {\n",
    "            'A': 4.0, 'B': 3.5, 'C': 3.0,\n",
    "            'D': 2.5, 'E': 2.0, 'F': 1.8, \n",
    "            'G': 1.5, 'Unknown': 2.0\n",
    "        }\n",
    "        buildings['expected_cop'] = buildings['energy_label_simple'].map(cop_by_label)\n",
    "        \n",
    "        # Initial asset assignment (most buildings don't have assets yet)\n",
    "        buildings['has_solar'] = False\n",
    "        buildings['has_battery'] = False\n",
    "        buildings['has_heat_pump'] = (buildings['energy_label_simple'].isin(['A', 'B'])) & \\\n",
    "                                     (np.random.random(len(buildings)) > 0.8)\n",
    "        buildings['heating_system'] = buildings.apply(\n",
    "            lambda x: 'heat_pump' if x['has_heat_pump'] else 'gas', axis=1\n",
    "        )\n",
    "        \n",
    "        # Some buildings might already have solar (simulate 5% adoption)\n",
    "        high_potential_mask = buildings['solar_potential'].isin(['high', 'medium'])\n",
    "        buildings.loc[high_potential_mask, 'has_solar'] = np.random.random(high_potential_mask.sum()) > 0.95\n",
    "        \n",
    "        # Batteries only for buildings with solar\n",
    "        buildings.loc[buildings['has_solar'], 'has_battery'] = np.random.random(buildings['has_solar'].sum()) > 0.7\n",
    "        \n",
    "        logger.info(f\"Building features calculated: {len(buildings)} buildings processed\")\n",
    "        logger.info(f\"  Solar potential - High: {(buildings['solar_potential']=='high').sum()}, \"\n",
    "                   f\"Medium: {(buildings['solar_potential']=='medium').sum()}\")\n",
    "        logger.info(f\"  Existing installations - Solar: {buildings['has_solar'].sum()}, \"\n",
    "                   f\"Battery: {buildings['has_battery'].sum()}, \"\n",
    "                   f\"Heat Pump: {buildings['has_heat_pump'].sum()}\")\n",
    "        \n",
    "        return buildings\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 4: CREATE EXISTING ASSET NODES\n",
    "    # ============================================\n",
    "    \n",
    "    def create_existing_assets(self):\n",
    "        \"\"\"Create asset nodes for buildings that already have installations\"\"\"\n",
    "        logger.info(\"Creating existing asset nodes...\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Existing solar systems\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building {has_solar: true})\n",
    "                CREATE (s:SolarSystem {\n",
    "                    system_id: 'SOLAR_EXISTING_' + toString(b.ogc_fid),\n",
    "                    building_id: b.ogc_fid,\n",
    "                    status: 'existing',\n",
    "                    installed_capacity_kwp: b.solar_capacity_kwp,\n",
    "                    installation_year: 2023,\n",
    "                    degradation_factor: 0.98,\n",
    "                    orientation_efficiency: \n",
    "                        CASE b.building_orientation_cardinal\n",
    "                            WHEN 'S' THEN 1.0\n",
    "                            WHEN 'SE' THEN 0.95\n",
    "                            WHEN 'SW' THEN 0.95\n",
    "                            ELSE 0.8\n",
    "                        END\n",
    "                })\n",
    "                CREATE (b)-[:HAS_INSTALLED {\n",
    "                    install_date: date('2023-01-01')\n",
    "                }]->(s)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            solar_count = result.single()['count']\n",
    "            \n",
    "            # Existing battery systems\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building {has_battery: true})\n",
    "                CREATE (bat:BatterySystem {\n",
    "                    system_id: 'BATTERY_EXISTING_' + toString(b.ogc_fid),\n",
    "                    building_id: b.ogc_fid,\n",
    "                    status: 'existing',\n",
    "                    installed_capacity_kwh: \n",
    "                        CASE \n",
    "                            WHEN b.area < 150 THEN 5.0\n",
    "                            WHEN b.area < 300 THEN 10.0\n",
    "                            ELSE 15.0\n",
    "                        END,\n",
    "                    power_rating_kw: \n",
    "                        CASE \n",
    "                            WHEN b.area < 150 THEN 2.5\n",
    "                            WHEN b.area < 300 THEN 5.0\n",
    "                            ELSE 7.5\n",
    "                        END,\n",
    "                    round_trip_efficiency: 0.9\n",
    "                })\n",
    "                CREATE (b)-[:HAS_INSTALLED {\n",
    "                    install_date: date('2023-01-01')\n",
    "                }]->(bat)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            battery_count = result.single()['count']\n",
    "            \n",
    "            # Existing heat pump systems\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building {has_heat_pump: true})\n",
    "                CREATE (hp:HeatPumpSystem {\n",
    "                    system_id: 'HP_EXISTING_' + toString(b.ogc_fid),\n",
    "                    building_id: b.ogc_fid,\n",
    "                    status: 'existing',\n",
    "                    expected_cop: b.expected_cop,\n",
    "                    heating_capacity_kw: b.area * 0.05,\n",
    "                    installation_year: 2022\n",
    "                })\n",
    "                CREATE (b)-[:HAS_INSTALLED {\n",
    "                    install_date: date('2022-01-01')\n",
    "                }]->(hp)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            hp_count = result.single()['count']\n",
    "            \n",
    "            self.stats['nodes_created']['ExistingSolar'] = solar_count\n",
    "            self.stats['nodes_created']['ExistingBattery'] = battery_count  \n",
    "            self.stats['nodes_created']['ExistingHeatPump'] = hp_count\n",
    "            self.stats['relationships_created']['HAS_INSTALLED'] = solar_count + battery_count + hp_count\n",
    "            \n",
    "        logger.info(f\"Created existing assets: {solar_count} solar, {battery_count} battery, {hp_count} heat pumps\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 5: LOAD TEMPORAL ENERGY DATA (UNCHANGED)\n",
    "    # ============================================\n",
    "    \n",
    "    def load_temporal_data(self, data_path: str):\n",
    "        \"\"\"Load time-series energy profiles from parquet\"\"\"\n",
    "        logger.info(\"Loading temporal energy data...\")\n",
    "        \n",
    "        # Load energy profiles from parquet\n",
    "        profiles = pd.read_parquet(f\"{data_path}/energy_profiles.parquet\")\n",
    "        \n",
    "        # Get unique timestamps\n",
    "        timestamps = profiles['timestamp'].unique()\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Create TimeSlot nodes\n",
    "            for i, ts in enumerate(timestamps):\n",
    "                dt = pd.to_datetime(ts)\n",
    "                session.run(\"\"\"\n",
    "                    CREATE (t:TimeSlot {\n",
    "                        slot_id: $slot_id,\n",
    "                        timestamp: datetime($timestamp),\n",
    "                        hour_of_day: $hour,\n",
    "                        day_of_week: $dow,\n",
    "                        is_weekend: $weekend,\n",
    "                        season: $season,\n",
    "                        time_of_day: $tod\n",
    "                    })\n",
    "                \"\"\",\n",
    "                slot_id=f\"TS_{i}\",\n",
    "                timestamp=dt.isoformat(),\n",
    "                hour=dt.hour,\n",
    "                dow=dt.dayofweek,\n",
    "                weekend=dt.dayofweek >= 5,\n",
    "                season=self._get_season(dt),\n",
    "                tod=self._get_time_of_day(dt.hour)\n",
    "                )\n",
    "            \n",
    "            self.stats['nodes_created']['TimeSlot'] = len(timestamps)\n",
    "            \n",
    "            # Create EnergyState nodes in batches\n",
    "            logger.info(\"Creating energy states (this may take a moment)...\")\n",
    "            \n",
    "            batch_size = 1000\n",
    "            state_count = 0\n",
    "            \n",
    "            for building_id in profiles['building_id'].unique():\n",
    "                building_data = profiles[profiles['building_id'] == building_id]\n",
    "                \n",
    "                states = []\n",
    "                for idx, row in building_data.iterrows():\n",
    "                    dt = pd.to_datetime(row['timestamp'])\n",
    "                    slot_id = f\"TS_{list(timestamps).index(row['timestamp'])}\"\n",
    "                    \n",
    "                    # Calculate net position\n",
    "                    net_demand = row['electricity_demand_kw'] - row['solar_generation_kw'] + \\\n",
    "                                row['battery_discharge_kw'] - row['battery_charge_kw']\n",
    "                    \n",
    "                    states.append({\n",
    "                        'state_id': f\"ES_{building_id}_{slot_id}\",\n",
    "                        'building_id': int(building_id),\n",
    "                        'timeslot_id': slot_id,\n",
    "                        'electricity_demand_kw': float(row['electricity_demand_kw']),\n",
    "                        'heating_demand_kw': float(row['heating_demand_kw']),\n",
    "                        'cooling_demand_kw': float(row['cooling_demand_kw']),\n",
    "                        'solar_generation_kw': float(row['solar_generation_kw']),\n",
    "                        'battery_soc_kwh': float(row['battery_soc_kwh']),\n",
    "                        'battery_charge_kw': float(row['battery_charge_kw']),\n",
    "                        'battery_discharge_kw': float(row['battery_discharge_kw']),\n",
    "                        'net_demand_kw': float(net_demand),\n",
    "                        'is_surplus': net_demand < 0,\n",
    "                        'export_potential_kw': max(0, -net_demand),\n",
    "                        'import_need_kw': max(0, net_demand)\n",
    "                    })\n",
    "                    \n",
    "                    if len(states) >= batch_size:\n",
    "                        self._create_energy_states_batch(session, states)\n",
    "                        state_count += len(states)\n",
    "                        states = []\n",
    "                \n",
    "                if states:\n",
    "                    self._create_energy_states_batch(session, states)\n",
    "                    state_count += len(states)\n",
    "            \n",
    "            self.stats['nodes_created']['EnergyState'] = state_count\n",
    "            \n",
    "            # Create relationships\n",
    "            logger.info(\"Creating temporal relationships...\")\n",
    "            \n",
    "            # Building -> EnergyState\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building), (e:EnergyState {building_id: b.ogc_fid})\n",
    "                CREATE (b)-[:HAS_STATE_AT]->(e)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            self.stats['relationships_created']['HAS_STATE_AT'] = result.single()['count']\n",
    "            \n",
    "            # EnergyState -> TimeSlot\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (e:EnergyState), (t:TimeSlot {slot_id: e.timeslot_id})\n",
    "                CREATE (e)-[:DURING]->(t)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            self.stats['relationships_created']['DURING'] = result.single()['count']\n",
    "            \n",
    "        logger.info(f\"Created {state_count} energy states with temporal relationships\")\n",
    "    \n",
    "    def _create_energy_states_batch(self, session, states):\n",
    "        \"\"\"Create energy state nodes in batch\"\"\"\n",
    "        session.run(\"\"\"\n",
    "            UNWIND $states as state\n",
    "            CREATE (e:EnergyState {\n",
    "                state_id: state.state_id,\n",
    "                building_id: state.building_id,\n",
    "                timeslot_id: state.timeslot_id,\n",
    "                electricity_demand_kw: state.electricity_demand_kw,\n",
    "                heating_demand_kw: state.heating_demand_kw,\n",
    "                cooling_demand_kw: state.cooling_demand_kw,\n",
    "                solar_generation_kw: state.solar_generation_kw,\n",
    "                battery_soc_kwh: state.battery_soc_kwh,\n",
    "                battery_charge_kw: state.battery_charge_kw,\n",
    "                battery_discharge_kw: state.battery_discharge_kw,\n",
    "                net_demand_kw: state.net_demand_kw,\n",
    "                is_surplus: state.is_surplus,\n",
    "                export_potential_kw: state.export_potential_kw,\n",
    "                import_need_kw: state.import_need_kw\n",
    "            })\n",
    "        \"\"\", states=states)\n",
    "    \n",
    "    def _get_season(self, dt):\n",
    "        \"\"\"Get season from datetime\"\"\"\n",
    "        month = dt.month\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'winter'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'summer'\n",
    "        else:\n",
    "            return 'fall'\n",
    "    \n",
    "    def _get_time_of_day(self, hour):\n",
    "        \"\"\"Categorize time of day\"\"\"\n",
    "        if 6 <= hour < 12:\n",
    "            return 'morning'\n",
    "        elif 12 <= hour < 18:\n",
    "            return 'afternoon'\n",
    "        elif 18 <= hour < 22:\n",
    "            return 'evening'\n",
    "        else:\n",
    "            return 'night'\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 6: IDENTIFY ASSET OPPORTUNITIES\n",
    "    # ============================================\n",
    "    \n",
    "    def identify_asset_opportunities(self):\n",
    "        \"\"\"Create nodes for potential solar, battery, and electrification\"\"\"\n",
    "        logger.info(\"Identifying asset deployment opportunities...\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Solar opportunities (for buildings without solar)\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                WHERE b.solar_potential IN ['high', 'medium']\n",
    "                  AND b.has_solar = false\n",
    "                CREATE (s:SolarSystem {\n",
    "                    system_id: 'SOLAR_POTENTIAL_' + toString(b.ogc_fid),\n",
    "                    building_id: b.ogc_fid,\n",
    "                    status: 'potential',\n",
    "                    potential_capacity_kwp: b.solar_capacity_kwp,\n",
    "                    recommended_capacity_kwp: \n",
    "                        CASE \n",
    "                            WHEN b.area < 150 THEN 4.0\n",
    "                            WHEN b.area < 300 THEN 6.0\n",
    "                            ELSE 10.0\n",
    "                        END,\n",
    "                    orientation_efficiency: \n",
    "                        CASE b.building_orientation_cardinal\n",
    "                            WHEN 'S' THEN 1.0\n",
    "                            WHEN 'SE' THEN 0.95\n",
    "                            WHEN 'SW' THEN 0.95\n",
    "                            WHEN 'E' THEN 0.85\n",
    "                            WHEN 'W' THEN 0.85\n",
    "                            ELSE 0.7\n",
    "                        END,\n",
    "                    payback_years: 7.5\n",
    "                })\n",
    "                CREATE (b)-[:CAN_INSTALL {\n",
    "                    feasibility_score: \n",
    "                        CASE b.solar_potential\n",
    "                            WHEN 'high' THEN 0.9\n",
    "                            WHEN 'medium' THEN 0.7\n",
    "                            ELSE 0.5\n",
    "                        END,\n",
    "                    priority: 'medium'\n",
    "                }]->(s)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            \n",
    "            solar_count = result.single()['count']\n",
    "            self.stats['nodes_created']['SolarPotential'] = solar_count\n",
    "            \n",
    "            # Battery opportunities\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                WHERE (b.solar_potential IN ['high', 'medium'] OR b.building_function = 'non_residential')\n",
    "                  AND b.has_battery = false\n",
    "                WITH b, \n",
    "                     CASE \n",
    "                         WHEN b.area < 150 THEN 5.0\n",
    "                         WHEN b.area < 300 THEN 10.0\n",
    "                         ELSE 20.0\n",
    "                     END as battery_size\n",
    "                CREATE (bat:BatterySystem {\n",
    "                    system_id: 'BATTERY_POTENTIAL_' + toString(b.ogc_fid),\n",
    "                    building_id: b.ogc_fid,\n",
    "                    status: 'potential',\n",
    "                    recommended_capacity_kwh: battery_size,\n",
    "                    power_rating_kw: battery_size / 4,\n",
    "                    round_trip_efficiency: 0.9,\n",
    "                    estimated_cycles_per_year: 250\n",
    "                })\n",
    "                CREATE (b)-[:CAN_INSTALL {\n",
    "                    feasibility_score: \n",
    "                        CASE \n",
    "                            WHEN b.has_solar OR b.solar_potential IN ['high', 'medium'] THEN 0.8\n",
    "                            ELSE 0.6\n",
    "                        END,\n",
    "                    requires_solar: NOT b.has_solar,\n",
    "                    priority: 'low'\n",
    "                }]->(bat)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            \n",
    "            battery_count = result.single()['count']\n",
    "            self.stats['nodes_created']['BatteryPotential'] = battery_count\n",
    "            \n",
    "            # Electrification opportunities (heat pumps)\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                WHERE b.energy_label_simple IN ['D', 'E', 'F', 'G']\n",
    "                  AND b.has_heat_pump = false\n",
    "                CREATE (hp:HeatPumpSystem {\n",
    "                    system_id: 'HP_POTENTIAL_' + toString(b.ogc_fid),\n",
    "                    building_id: b.ogc_fid,\n",
    "                    status: 'potential',\n",
    "                    expected_cop: b.expected_cop,\n",
    "                    heating_capacity_kw: b.area * 0.05,\n",
    "                    upgrade_required: b.electrification_feasibility = 'upgrade_needed',\n",
    "                    estimated_annual_savings_euro: \n",
    "                        CASE b.energy_label_simple\n",
    "                            WHEN 'G' THEN 2000\n",
    "                            WHEN 'F' THEN 1500\n",
    "                            WHEN 'E' THEN 1000\n",
    "                            ELSE 500\n",
    "                        END\n",
    "                })\n",
    "                CREATE (b)-[:SHOULD_ELECTRIFY {\n",
    "                    priority: \n",
    "                        CASE b.energy_label_simple\n",
    "                            WHEN 'G' THEN 1\n",
    "                            WHEN 'F' THEN 2\n",
    "                            WHEN 'E' THEN 3\n",
    "                            WHEN 'D' THEN 4\n",
    "                            ELSE 5\n",
    "                        END,\n",
    "                    expected_cop: b.expected_cop,\n",
    "                    requires_insulation_upgrade: b.energy_label_simple IN ['F', 'G']\n",
    "                }]->(hp)\n",
    "                RETURN count(*) as count\n",
    "            \"\"\")\n",
    "            \n",
    "            hp_count = result.single()['count']\n",
    "            self.stats['nodes_created']['HeatPumpPotential'] = hp_count\n",
    "            \n",
    "        logger.info(f\"Identified opportunities: {solar_count} solar, {battery_count} battery, {hp_count} heat pumps\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 7: CALCULATE BASELINE METRICS\n",
    "    # ============================================\n",
    "    \n",
    "    def calculate_baseline_metrics(self):\n",
    "        \"\"\"Calculate current state metrics for comparison after GNN optimization\"\"\"\n",
    "        logger.info(\"Calculating baseline metrics...\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Building-level statistics\n",
    "            session.run(\"\"\"\n",
    "                MATCH (b:Building)-[:HAS_STATE_AT]->(e:EnergyState)\n",
    "                WITH b, \n",
    "                    max(e.electricity_demand_kw) as peak_demand,\n",
    "                    avg(e.electricity_demand_kw) as avg_demand,\n",
    "                    stdev(e.electricity_demand_kw) as demand_std,\n",
    "                    max(e.solar_generation_kw) as peak_solar,\n",
    "                    avg(e.net_demand_kw) as avg_net_demand\n",
    "                SET b.peak_demand_kw = peak_demand,\n",
    "                    b.avg_demand_kw = avg_demand,\n",
    "                    b.load_factor = avg_demand / CASE WHEN peak_demand > 0 THEN peak_demand ELSE 1 END,\n",
    "                    b.demand_variability = demand_std / CASE WHEN avg_demand > 0 THEN avg_demand ELSE 1 END,\n",
    "                    b.peak_solar_kw = peak_solar,\n",
    "                    b.avg_net_demand_kw = avg_net_demand,\n",
    "                    b.self_consumption_ratio = \n",
    "                        CASE WHEN b.has_solar \n",
    "                        THEN (avg_demand - avg_net_demand) / CASE WHEN avg_demand > 0 THEN avg_demand ELSE 1 END\n",
    "                        ELSE 0 END\n",
    "            \"\"\")\n",
    "            \n",
    "            # LV Cable Group baseline statistics\n",
    "            session.run(\"\"\"\n",
    "                MATCH (g:CableGroup {voltage_level: 'LV'})<-[:CONNECTED_TO]-(b:Building)\n",
    "                WITH g, \n",
    "                    count(b) as building_count,\n",
    "                    sum(b.peak_demand_kw) as total_peak_demand,\n",
    "                    avg(b.peak_demand_kw) as avg_building_peak,\n",
    "                    sum(b.avg_demand_kw) as total_avg_demand,\n",
    "                    sum(CASE WHEN b.has_solar THEN 1 ELSE 0 END) as solar_count,\n",
    "                    sum(CASE WHEN b.has_battery THEN 1 ELSE 0 END) as battery_count,\n",
    "                    sum(CASE WHEN b.has_heat_pump THEN 1 ELSE 0 END) as hp_count,\n",
    "                    collect(DISTINCT b.building_function) as building_types\n",
    "                SET g.baseline_building_count = building_count,\n",
    "                    g.baseline_peak_kw = total_peak_demand,\n",
    "                    g.baseline_avg_demand_kw = total_avg_demand,\n",
    "                    g.baseline_load_factor = total_avg_demand / CASE WHEN total_peak_demand > 0 THEN total_peak_demand ELSE 1 END,\n",
    "                    g.baseline_solar_penetration = toFloat(solar_count) / building_count,\n",
    "                    g.baseline_battery_penetration = toFloat(battery_count) / building_count,\n",
    "                    g.baseline_hp_penetration = toFloat(hp_count) / building_count,\n",
    "                    g.baseline_diversity = size(building_types)\n",
    "            \"\"\")\n",
    "            \n",
    "            # Transformer baseline\n",
    "            session.run(\"\"\"\n",
    "                MATCH (t:Transformer)<-[:CONNECTS_TO]-(g:CableGroup {voltage_level: 'LV'})\n",
    "                WITH t, \n",
    "                    count(g) as lv_count,\n",
    "                    sum(g.baseline_peak_kw) as total_peak,\n",
    "                    sum(g.baseline_building_count) as total_buildings\n",
    "                SET t.baseline_lv_count = lv_count,\n",
    "                    t.baseline_peak_kw = total_peak,\n",
    "                    t.baseline_building_count = total_buildings\n",
    "            \"\"\")\n",
    "            \n",
    "            # System-wide baseline\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                WITH count(b) as total_buildings,\n",
    "                    sum(b.peak_demand_kw) as system_peak,\n",
    "                    avg(b.load_factor) as avg_load_factor,\n",
    "                    sum(CASE WHEN b.has_solar THEN 1 ELSE 0 END) as solar_buildings,\n",
    "                    sum(CASE WHEN b.has_battery THEN 1 ELSE 0 END) as battery_buildings,\n",
    "                    sum(CASE WHEN b.has_heat_pump THEN 1 ELSE 0 END) as hp_buildings\n",
    "                CREATE (s:SystemBaseline {\n",
    "                    id: 'BASELINE_' + toString(datetime()),\n",
    "                    timestamp: datetime(),\n",
    "                    total_buildings: total_buildings,\n",
    "                    system_peak_kw: system_peak,\n",
    "                    avg_load_factor: avg_load_factor,\n",
    "                    solar_penetration: toFloat(solar_buildings) / total_buildings,\n",
    "                    battery_penetration: toFloat(battery_buildings) / total_buildings,\n",
    "                    hp_penetration: toFloat(hp_buildings) / total_buildings,\n",
    "                    description: 'Pre-GNN optimization baseline'\n",
    "                })\n",
    "                RETURN total_buildings, system_peak, avg_load_factor\n",
    "            \"\"\")\n",
    "            \n",
    "            baseline = result.single()\n",
    "            if baseline:\n",
    "                total_buildings = baseline['total_buildings'] or 0\n",
    "                system_peak = baseline['system_peak'] or 0\n",
    "                avg_load_factor = baseline['avg_load_factor'] or 0\n",
    "                \n",
    "                logger.info(f\"Baseline: {total_buildings} buildings, \"\n",
    "                        f\"{system_peak:.0f} kW peak, \"\n",
    "                        f\"{avg_load_factor:.3f} load factor\")\n",
    "            \n",
    "    # ============================================\n",
    "    # STEP 8: ADD METADATA\n",
    "    # ============================================\n",
    "    \n",
    "    def add_metadata(self):\n",
    "        \"\"\"Add metadata about the KG creation\"\"\"\n",
    "        logger.info(\"Adding metadata...\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            metadata = {\n",
    "                'creation_timestamp': datetime.now().isoformat(),\n",
    "                'total_nodes': sum(self.stats['nodes_created'].values()),\n",
    "                'total_relationships': sum(self.stats['relationships_created'].values()),\n",
    "                'node_types': self.stats['nodes_created'],\n",
    "                'relationship_types': self.stats['relationships_created']\n",
    "            }\n",
    "            \n",
    "            session.run(\"\"\"\n",
    "                CREATE (m:Metadata {\n",
    "                    id: 'PRE_GNN_METADATA',\n",
    "                    created_at: datetime($timestamp),\n",
    "                    total_nodes: $nodes,\n",
    "                    total_relationships: $rels,\n",
    "                    node_breakdown: $node_types,\n",
    "                    relationship_breakdown: $rel_types,\n",
    "                    data_source: 'PostgreSQL',\n",
    "                    version: '2.0',\n",
    "                    stage: 'pre_gnn',\n",
    "                    description: 'Knowledge graph with rich grid infrastructure before GNN optimization'\n",
    "                })\n",
    "            \"\"\",\n",
    "            timestamp=metadata['creation_timestamp'],\n",
    "            nodes=metadata['total_nodes'],\n",
    "            rels=metadata['total_relationships'],\n",
    "            node_types=json.dumps(metadata['node_types']),\n",
    "            rel_types=json.dumps(metadata['relationship_types'])\n",
    "            )\n",
    "            \n",
    "        logger.info(\"Metadata added\")\n",
    "    \n",
    "    # ============================================\n",
    "    # MAIN EXECUTION METHOD\n",
    "    # ============================================\n",
    "    \n",
    "    def build_complete_graph(self, data_path: str, clear_first: bool = True):\n",
    "        \"\"\"Build complete knowledge graph from PostgreSQL database (Pre-GNN version)\"\"\"\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        logger.info(\"=\"*50)\n",
    "        logger.info(\"Starting Knowledge Graph Construction (Pre-GNN)\")\n",
    "        logger.info(\"=\"*50)\n",
    "        \n",
    "        try:\n",
    "            # Clear database if requested\n",
    "            if clear_first:\n",
    "                self.clear_database()\n",
    "            \n",
    "            # Build graph step by step\n",
    "            self.create_schema()\n",
    "            self.load_grid_infrastructure()  # From PostgreSQL\n",
    "            self.load_buildings()  # From PostgreSQL\n",
    "            self.create_existing_assets()\n",
    "            self.load_temporal_data(data_path)  # Still from parquet\n",
    "            self.identify_asset_opportunities()\n",
    "            self.calculate_baseline_metrics()\n",
    "            self.add_metadata()\n",
    "            \n",
    "            # Calculate total time\n",
    "            end_time = datetime.now()\n",
    "            total_time = (end_time - start_time).total_seconds()\n",
    "            \n",
    "            # Print summary\n",
    "            logger.info(\"=\"*50)\n",
    "            logger.info(\"Pre-GNN Knowledge Graph Construction Complete!\")\n",
    "            logger.info(\"=\"*50)\n",
    "            logger.info(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "            logger.info(\"\\nNodes created:\")\n",
    "            for node_type, count in self.stats['nodes_created'].items():\n",
    "                logger.info(f\"  {node_type}: {count:,}\")\n",
    "            logger.info(f\"  TOTAL: {sum(self.stats['nodes_created'].values()):,}\")\n",
    "            \n",
    "            logger.info(\"\\nRelationships created:\")\n",
    "            for rel_type, count in self.stats['relationships_created'].items():\n",
    "                logger.info(f\"  {rel_type}: {count:,}\")\n",
    "            logger.info(f\"  TOTAL: {sum(self.stats['relationships_created'].values()):,}\")\n",
    "            \n",
    "            logger.info(\"\\n⚠️ Note: Complementarity analysis and clustering will be added after GNN processing\")\n",
    "            \n",
    "            return self.stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error building knowledge graph: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# ============================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    NEO4J_URI = \"bolt://localhost:7687\"\n",
    "    NEO4J_USER = \"neo4j\"\n",
    "    NEO4J_PASSWORD = \"aminasad\"  # Change this to your password\n",
    "    \n",
    "    # PostgreSQL configuration\n",
    "    PG_HOST = \"localhost\"\n",
    "    PG_DATABASE = \"research\"  # Your database name\n",
    "    PG_USER = \"aminj\"\n",
    "    PG_PASSWORD = \"Aminej@geodan!\"  # Change this\n",
    "\n",
    "    DATA_PATH = \"mimic_data\"  # For parquet files\n",
    "    \n",
    "    # Create builder and construct graph\n",
    "    builder = EnergyKnowledgeGraphBuilder(\n",
    "        NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD,\n",
    "        PG_HOST, PG_DATABASE, PG_USER, PG_PASSWORD\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Build complete knowledge graph\n",
    "        stats = builder.build_complete_graph(DATA_PATH, clear_first=True)\n",
    "        \n",
    "        # Run validation queries\n",
    "        with builder.driver.session() as session:\n",
    "            # Check grid infrastructure\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (n:GridComponent)\n",
    "                RETURN n.component_type as type, count(*) as count\n",
    "                ORDER BY count DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"Grid Infrastructure Summary:\")\n",
    "            print(\"=\"*50)\n",
    "            for record in result:\n",
    "                print(f\"{record['type']}: {record['count']} components\")\n",
    "            \n",
    "            # Check LV groups with buildings\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (g:CableGroup {voltage_level: 'LV'})\n",
    "                OPTIONAL MATCH (g)<-[:CONNECTED_TO]-(b:Building)\n",
    "                WITH g, count(b) as buildings\n",
    "                RETURN g.group_id as group_id,\n",
    "                       buildings,\n",
    "                       g.baseline_peak_kw as peak_kw,\n",
    "                       g.baseline_solar_penetration as solar_pen\n",
    "                ORDER BY buildings DESC\n",
    "                LIMIT 10\n",
    "            \"\"\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"Top 10 LV Groups by Building Count:\")\n",
    "            print(\"=\"*50)\n",
    "            for record in result:\n",
    "                print(f\"{record['group_id']}: {record['buildings']} buildings, \"\n",
    "                      f\"Peak: {record['peak_kw']:.0f} kW, \"\n",
    "                      f\"Solar: {record['solar_pen']:.1%}\" if record['peak_kw'] else \"No metrics yet\")\n",
    "            \n",
    "            # Check building connection quality\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                RETURN b.connection_type as type, \n",
    "                       count(*) as count,\n",
    "                       avg(b.connection_distance_m) as avg_distance\n",
    "                ORDER BY count DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"Building Connection Quality:\")\n",
    "            print(\"=\"*50)\n",
    "            for record in result:\n",
    "                print(f\"{record['type']}: {record['count']} buildings, \"\n",
    "                      f\"Avg distance: {record['avg_distance']:.1f}m\")\n",
    "            \n",
    "            # Check opportunities\n",
    "            result = session.run(\"\"\"\n",
    "                OPTIONAL MATCH (s:SolarSystem {status: 'potential'})\n",
    "                WITH count(s) as solar_opp\n",
    "                OPTIONAL MATCH (b:BatterySystem {status: 'potential'})\n",
    "                WITH solar_opp, count(b) as battery_opp\n",
    "                OPTIONAL MATCH (h:HeatPumpSystem {status: 'potential'})\n",
    "                RETURN solar_opp, battery_opp, count(h) as hp_opp\n",
    "            \"\"\")\n",
    "            \n",
    "            opp = result.single()\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"Deployment Opportunities Identified:\")\n",
    "            print(\"=\"*50)\n",
    "            if opp:\n",
    "                print(f\"Solar: {opp['solar_opp']} buildings\")\n",
    "                print(f\"Battery: {opp['battery_opp']} buildings\")\n",
    "                print(f\"Heat Pump: {opp['hp_opp']} buildings\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        builder.close()\n",
    "    \n",
    "    print(\"\\n✅ Pre-GNN Knowledge Graph construction complete!\")\n",
    "    print(\"Ready for GNN processing to discover complementarity and optimal clustering\")\n",
    "    print(\"You can explore the graph in Neo4j Browser at http://localhost:7474\")\n",
    "    \n",
    "    \"\"\"\n",
    "    # After GNN runs, you'll add:\n",
    "    1. COMPLEMENTS relationships (discovered by GNN)\n",
    "    2. EnergyCluster nodes (optimized groupings)\n",
    "    3. TRADES_ENERGY_WITH relationships\n",
    "    4. DeploymentScenario nodes (GNN recommendations)\n",
    "    5. Performance metrics comparing to baseline\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5058921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 03:28:21,132 - INFO - Connected to Neo4j and PostgreSQL for adjacency update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Adjacency Module (Part 2) using PostgreSQL data...\n",
      "Connecting to PostgreSQL database: research\n",
      "Connecting to Neo4j at: bolt://localhost:7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 03:28:23,242 - INFO - KG Status: {'buildings_exist': True, 'has_shared_walls': True, 'adjacencies_exist': False, 'building_count': 1185}\n",
      "2025-08-18 03:28:23,243 - INFO - Shared wall data already exists in Neo4j\n",
      "2025-08-18 03:28:23,243 - INFO - Creating adjacency relationships...\n",
      "2025-08-18 03:28:23,719 - INFO - Created 514 adjacency relationships (257 pairs)\n",
      "2025-08-18 03:28:23,719 - INFO - Validating adjacency patterns...\n",
      "2025-08-18 03:28:23,745 - INFO - Creating natural adjacency clusters...\n",
      "2025-08-18 03:28:23,788 - INFO - Creating row house clusters...\n",
      "2025-08-18 03:28:24,021 - INFO - Created 327 row house clusters\n",
      "2025-08-18 03:28:24,022 - INFO - Creating corner/courtyard clusters...\n",
      "2025-08-18 03:28:24,065 - INFO - Created 0 corner/courtyard clusters\n",
      "2025-08-18 03:28:24,066 - INFO - Creating apartment clusters...\n",
      "2025-08-18 03:28:24,283 - INFO - Created 0 apartment clusters\n",
      "2025-08-18 03:28:24,283 - INFO - Created 327 adjacency clusters total\n",
      "2025-08-18 03:28:24,284 - INFO - Enhancing building metrics with adjacency data...\n",
      "2025-08-18 03:28:24,394 - INFO - Building metrics enhanced with adjacency data\n",
      "2025-08-18 03:28:24,401 - INFO - \n",
      "============================================================\n",
      "2025-08-18 03:28:24,401 - INFO - ADJACENCY UPDATE REPORT\n",
      "2025-08-18 03:28:24,401 - INFO - ============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Statistics:\n",
      "  Total buildings: 1517\n",
      "  With shared walls: 1229\n",
      "  With adjacencies found: 332\n",
      "  Average adjacencies: 0.68\n",
      "\n",
      "Adjacency Type Distribution:\n",
      "  MIDDLE_ROW: 823\n",
      "  END_ROW: 330\n",
      "  ISOLATED: 288\n",
      "  CORNER: 76\n",
      "\n",
      "Housing Type Adjacency Analysis:\n",
      "  unknown: 848 buildings, avg 1.2 adjacencies\n",
      "  Appartement: 288 buildings, avg 0.0 adjacencies\n",
      "  Tussen of geschakelde woning: 272 buildings, avg 0.1 adjacencies\n",
      "  Hoekwoning: 68 buildings, avg 0.0 adjacencies\n",
      "  Vrijstaande woning: 36 buildings, avg 0.0 adjacencies\n",
      "  Tweeonder1kap: 5 buildings, avg 0.0 adjacencies\n",
      "\n",
      "Adjacency Relationships:\n",
      "  Total pairs: 257\n",
      "  Avg distance: 3.12 m\n",
      "  Avg strength: 6.77\n",
      "  Avg match quality: 1.00\n",
      "  Avg complementarity: 1.00\n",
      "\n",
      "Adjacency Clusters:\n",
      "  ROW_HOUSES: 327 clusters, avg size: 6.8, solar pen: 0.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 03:28:24,732 - INFO - Total processing time: 3.60 seconds\n",
      "2025-08-18 03:28:24,733 - INFO - Connections closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top LV Groups by Adjacency Ratio:\n",
      "  LV_GROUP_0002: 4/5 (80.0%)\n",
      "  LV_GROUP_0024: 9/12 (75.0%)\n",
      "  LV_GROUP_0021: 7/11 (63.6%)\n",
      "  LV_GROUP_0026: 3/5 (60.0%)\n",
      "  LV_GROUP_0023: 4/7 (57.1%)\n",
      "  LV_GROUP_0127: 5/9 (55.6%)\n",
      "  LV_GROUP_0140: 6/11 (54.5%)\n",
      "  LV_GROUP_0022: 6/13 (46.2%)\n",
      "  LV_GROUP_0120: 10/23 (43.5%)\n",
      "  LV_GROUP_0119: 5/13 (38.5%)\n",
      "\n",
      "Top Complementarity Pairs:\n",
      "  Buildings 4804268-4804269: residential/residential, Tussen of geschakelde woning/Tussen of geschakelde woning, potential: 1.81\n",
      "  Buildings 4804268-4804269: residential/residential, Tussen of geschakelde woning/Tussen of geschakelde woning, potential: 1.81\n",
      "\n",
      "Validation Results:\n",
      "  middle_row_type: 141/823 (17.1% accuracy, avg: 1.2)\n",
      "  reciprocal: 257/257 (100.0% accuracy)\n",
      "\n",
      "============================================================\n",
      "ADJACENCY UPDATE COMPLETE\n",
      "============================================================\n",
      "\n",
      "✅ Adjacency update completed successfully!\n",
      "Your KG now has:\n",
      "  - ADJACENT_TO relationships with energy implications\n",
      "  - Natural adjacency clusters (row houses, corners, apartments)\n",
      "  - Enhanced complementarity potential for adjacent buildings\n",
      "  - Thermal coupling metrics\n",
      "  - Validation against housing types (woningtype)\n",
      "\n",
      "Ready for GNN processing with adjacency-aware features!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Adjacency Module for Energy KG - Part 2\n",
    "Updates existing Knowledge Graph with adjacency relationships\n",
    "Uses PostgreSQL database (same as Part 1) instead of CSV\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neo4j import GraphDatabase\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from decimal import Decimal\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class AdjacencyUpdater:\n",
    "    \"\"\"Add adjacency relationships to existing Knowledge Graph using PostgreSQL data\"\"\"\n",
    "    \n",
    "    def __init__(self, neo4j_uri: str, neo4j_user: str, neo4j_password: str,\n",
    "                 pg_host: str, pg_database: str, pg_user: str, pg_password: str):\n",
    "        \"\"\"Initialize Neo4j and PostgreSQL connections (same as Part 1)\"\"\"\n",
    "        # Neo4j connection\n",
    "        self.driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))\n",
    "        \n",
    "        # PostgreSQL connection (same as Part 1)\n",
    "        self.pg_conn = psycopg2.connect(\n",
    "            host=pg_host,\n",
    "            database=pg_database,\n",
    "            user=pg_user,\n",
    "            password=pg_password,\n",
    "            port=5433\n",
    "        )\n",
    "        \n",
    "        self.stats = {\n",
    "            'relationships_created': 0,\n",
    "            'clusters_created': 0,\n",
    "            'nodes_updated': 0,\n",
    "            'validation_results': {}\n",
    "        }\n",
    "        logger.info(f\"Connected to Neo4j and PostgreSQL for adjacency update\")\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close database connections\"\"\"\n",
    "        self.driver.close()\n",
    "        self.pg_conn.close()\n",
    "        logger.info(\"Connections closed\")\n",
    "    \n",
    "    def convert_decimals(self, record):\n",
    "        \"\"\"Convert Decimal types to float for Neo4j compatibility (from Part 1)\"\"\"\n",
    "        if isinstance(record, dict):\n",
    "            return {k: float(v) if isinstance(v, Decimal) else v for k, v in record.items()}\n",
    "        elif isinstance(record, list):\n",
    "            return [self.convert_decimals(item) for item in record]\n",
    "        else:\n",
    "            return float(record) if isinstance(record, Decimal) else record\n",
    "    \n",
    "    def safe_float(self, value, default=0.0) -> float:\n",
    "        \"\"\"Safely convert value to float, handling None and other edge cases\"\"\"\n",
    "        if value is None:\n",
    "            return default\n",
    "        try:\n",
    "            return float(value)\n",
    "        except (TypeError, ValueError):\n",
    "            return default\n",
    "    \n",
    "    def safe_int(self, value, default=0) -> int:\n",
    "        \"\"\"Safely convert value to int, handling None and other edge cases\"\"\"\n",
    "        if value is None:\n",
    "            return default\n",
    "        try:\n",
    "            return int(value)\n",
    "        except (TypeError, ValueError):\n",
    "            return default\n",
    "    \n",
    "    def check_kg_status(self) -> Dict:\n",
    "        \"\"\"Check if KG exists and has required data\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                RETURN \n",
    "                    count(b) as building_count,\n",
    "                    count(b.north_shared_length) as has_shared_wall_data,\n",
    "                    exists((b)-[:ADJACENT_TO]-()) as has_adjacencies\n",
    "                LIMIT 1\n",
    "            \"\"\")\n",
    "            \n",
    "            status = result.single()\n",
    "            \n",
    "            return {\n",
    "                'buildings_exist': status['building_count'] > 0,\n",
    "                'has_shared_walls': status['has_shared_wall_data'] > 0,\n",
    "                'adjacencies_exist': status['has_adjacencies'],\n",
    "                'building_count': status['building_count']\n",
    "            }\n",
    "    \n",
    "    def update_shared_wall_data_from_postgres(self):\n",
    "        \"\"\"Update existing Neo4j buildings with shared wall data from PostgreSQL\"\"\"\n",
    "        logger.info(\"Updating buildings with shared wall data from PostgreSQL...\")\n",
    "        \n",
    "        with self.pg_conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "            # Query buildings with shared wall data from PostgreSQL\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    b.ogc_fid,\n",
    "                    -- Shared wall lengths (handle NULLs with COALESCE)\n",
    "                    COALESCE(b.north_shared_length, 0) as north_shared_length,\n",
    "                    COALESCE(b.south_shared_length, 0) as south_shared_length,\n",
    "                    COALESCE(b.east_shared_length, 0) as east_shared_length,\n",
    "                    COALESCE(b.west_shared_length, 0) as west_shared_length,\n",
    "                    -- Facade lengths (handle NULLs with COALESCE)\n",
    "                    COALESCE(b.north_facade_length, 10) as north_facade_length,\n",
    "                    COALESCE(b.south_facade_length, 10) as south_facade_length,\n",
    "                    COALESCE(b.east_facade_length, 10) as east_facade_length,\n",
    "                    COALESCE(b.west_facade_length, 10) as west_facade_length,\n",
    "                    -- Calculate derived fields\n",
    "                    (CASE WHEN b.north_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                     CASE WHEN b.south_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                     CASE WHEN b.east_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                     CASE WHEN b.west_shared_length > 0 THEN 1 ELSE 0 END) as num_shared_walls,\n",
    "                    (COALESCE(b.north_shared_length, 0) + \n",
    "                     COALESCE(b.south_shared_length, 0) + \n",
    "                     COALESCE(b.east_shared_length, 0) + \n",
    "                     COALESCE(b.west_shared_length, 0)) as total_shared_length,\n",
    "                    -- Adjacency type classification\n",
    "                    CASE \n",
    "                        WHEN (CASE WHEN b.north_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.south_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.east_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.west_shared_length > 0 THEN 1 ELSE 0 END) = 0 \n",
    "                        THEN 'ISOLATED'\n",
    "                        \n",
    "                        WHEN (b.north_shared_length > 0 AND b.south_shared_length > 0) OR\n",
    "                             (b.east_shared_length > 0 AND b.west_shared_length > 0)\n",
    "                        THEN 'MIDDLE_ROW'\n",
    "                        \n",
    "                        WHEN (CASE WHEN b.north_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.south_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.east_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.west_shared_length > 0 THEN 1 ELSE 0 END) = 2\n",
    "                        THEN 'CORNER'\n",
    "                        \n",
    "                        WHEN (CASE WHEN b.north_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.south_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.east_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.west_shared_length > 0 THEN 1 ELSE 0 END) = 1\n",
    "                        THEN 'END_ROW'\n",
    "                        \n",
    "                        WHEN (CASE WHEN b.north_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.south_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.east_shared_length > 0 THEN 1 ELSE 0 END +\n",
    "                              CASE WHEN b.west_shared_length > 0 THEN 1 ELSE 0 END) >= 3\n",
    "                        THEN 'COURTYARD'\n",
    "                        \n",
    "                        ELSE 'UNKNOWN'\n",
    "                    END as adjacency_type,\n",
    "                    -- Additional context\n",
    "                    b.woningtype,\n",
    "                    b.area\n",
    "                FROM amin.buildings_1_deducted b\n",
    "                JOIN amin_grid.tlip_building_connections bc \n",
    "                    ON b.ogc_fid = bc.building_id\n",
    "                WHERE b.area > 10 \n",
    "                    AND b.pand_geom IS NOT NULL\n",
    "                    AND bc.connected_group_id IS NOT NULL\n",
    "            \"\"\")\n",
    "            \n",
    "            buildings = [self.convert_decimals(row) for row in cursor.fetchall()]\n",
    "        \n",
    "        # Update Neo4j buildings with shared wall data\n",
    "        with self.driver.session() as session:\n",
    "            updated = 0\n",
    "            batch_size = 500\n",
    "            batch = []\n",
    "            \n",
    "            for building in buildings:\n",
    "                # Use safe conversion functions to handle None values\n",
    "                batch.append({\n",
    "                    'ogc_fid': self.safe_int(building['ogc_fid']),\n",
    "                    'north_shared': self.safe_float(building['north_shared_length'], 0),\n",
    "                    'south_shared': self.safe_float(building['south_shared_length'], 0),\n",
    "                    'east_shared': self.safe_float(building['east_shared_length'], 0),\n",
    "                    'west_shared': self.safe_float(building['west_shared_length'], 0),\n",
    "                    'north_facade': self.safe_float(building['north_facade_length'], 10),\n",
    "                    'south_facade': self.safe_float(building['south_facade_length'], 10),\n",
    "                    'east_facade': self.safe_float(building['east_facade_length'], 10),\n",
    "                    'west_facade': self.safe_float(building['west_facade_length'], 10),\n",
    "                    'num_shared': self.safe_int(building['num_shared_walls'], 0),\n",
    "                    'total_shared': self.safe_float(building['total_shared_length'], 0),\n",
    "                    'adj_type': building.get('adjacency_type', 'UNKNOWN') or 'UNKNOWN',\n",
    "                    'housing_type': building.get('woningtype', 'unknown') or 'unknown'\n",
    "                })\n",
    "                \n",
    "                if len(batch) >= batch_size:\n",
    "                    result = session.run(\"\"\"\n",
    "                        UNWIND $batch as building\n",
    "                        MATCH (b:Building {ogc_fid: building.ogc_fid})\n",
    "                        SET b.north_shared_length = building.north_shared,\n",
    "                            b.south_shared_length = building.south_shared,\n",
    "                            b.east_shared_length = building.east_shared,\n",
    "                            b.west_shared_length = building.west_shared,\n",
    "                            b.north_facade_length = building.north_facade,\n",
    "                            b.south_facade_length = building.south_facade,\n",
    "                            b.east_facade_length = building.east_facade,\n",
    "                            b.west_facade_length = building.west_facade,\n",
    "                            b.num_shared_walls = building.num_shared,\n",
    "                            b.total_shared_length = building.total_shared,\n",
    "                            b.adjacency_type = building.adj_type,\n",
    "                            b.woningtype = building.housing_type\n",
    "                        RETURN count(b) as updated_count\n",
    "                    \"\"\", batch=batch)\n",
    "                    \n",
    "                    single_result = result.single()\n",
    "                    if single_result:\n",
    "                        updated += single_result['updated_count']\n",
    "                    batch = []\n",
    "            \n",
    "            # Process remaining batch\n",
    "            if batch:\n",
    "                result = session.run(\"\"\"\n",
    "                    UNWIND $batch as building\n",
    "                    MATCH (b:Building {ogc_fid: building.ogc_fid})\n",
    "                    SET b.north_shared_length = building.north_shared,\n",
    "                        b.south_shared_length = building.south_shared,\n",
    "                        b.east_shared_length = building.east_shared,\n",
    "                        b.west_shared_length = building.west_shared,\n",
    "                        b.north_facade_length = building.north_facade,\n",
    "                        b.south_facade_length = building.south_facade,\n",
    "                        b.east_facade_length = building.east_facade,\n",
    "                        b.west_facade_length = building.west_facade,\n",
    "                        b.num_shared_walls = building.num_shared,\n",
    "                        b.total_shared_length = building.total_shared,\n",
    "                        b.adjacency_type = building.adj_type,\n",
    "                        b.woningtype = building.housing_type\n",
    "                    RETURN count(b) as updated_count\n",
    "                \"\"\", batch=batch)\n",
    "                \n",
    "                single_result = result.single()\n",
    "                if single_result:\n",
    "                    updated += single_result['updated_count']\n",
    "            \n",
    "            self.stats['nodes_updated'] = updated\n",
    "            logger.info(f\"Updated {updated} buildings with shared wall data from PostgreSQL\")\n",
    "    \n",
    "    def create_adjacency_relationships(self):\n",
    "        \"\"\"Find and create ADJACENT_TO relationships between buildings\"\"\"\n",
    "        logger.info(\"Creating adjacency relationships...\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Clear any existing adjacency relationships first\n",
    "            session.run(\"MATCH ()-[r:ADJACENT_TO]-() DELETE r\")\n",
    "            \n",
    "            # Create relationships using spatial proximity and shared walls\n",
    "            result = session.run(\"\"\"\n",
    "                // Find all buildings with shared walls\n",
    "                MATCH (b1:Building)\n",
    "                WHERE b1.num_shared_walls > 0\n",
    "                \n",
    "                // Find potential neighbors in same LV group\n",
    "                MATCH (b2:Building)\n",
    "                WHERE b1.ogc_fid < b2.ogc_fid  // Process each pair only once\n",
    "                AND b1.lv_group_id = b2.lv_group_id  // Same LV network\n",
    "                AND b2.num_shared_walls > 0\n",
    "                \n",
    "                // Calculate distance (must be very close for true adjacency)\n",
    "                WITH b1, b2, \n",
    "                    sqrt((b2.x - b1.x)^2 + (b2.y - b1.y)^2) as distance\n",
    "                WHERE distance < 5  // Reduced to 5m for true adjacency\n",
    "                \n",
    "                // Check for matching shared walls\n",
    "                WITH b1, b2, distance,\n",
    "                    CASE \n",
    "                        // North-South match\n",
    "                        WHEN b1.north_shared_length > 0 AND b2.south_shared_length > 0 \n",
    "                            AND b2.y > b1.y AND abs(b2.x - b1.x) < 3\n",
    "                        THEN {\n",
    "                            pair: 'north-south',\n",
    "                            b1_wall: 'north',\n",
    "                            b2_wall: 'south',\n",
    "                            b1_length: b1.north_shared_length,\n",
    "                            b2_length: b2.south_shared_length,\n",
    "                            match_quality: \n",
    "                                CASE \n",
    "                                    WHEN b1.north_shared_length < b2.south_shared_length \n",
    "                                    THEN b1.north_shared_length / b2.south_shared_length\n",
    "                                    ELSE b2.south_shared_length / b1.north_shared_length\n",
    "                                END\n",
    "                        }\n",
    "                        // South-North match\n",
    "                        WHEN b1.south_shared_length > 0 AND b2.north_shared_length > 0\n",
    "                            AND b2.y < b1.y AND abs(b2.x - b1.x) < 3\n",
    "                        THEN {\n",
    "                            pair: 'south-north',\n",
    "                            b1_wall: 'south',\n",
    "                            b2_wall: 'north',\n",
    "                            b1_length: b1.south_shared_length,\n",
    "                            b2_length: b2.north_shared_length,\n",
    "                            match_quality: \n",
    "                                CASE \n",
    "                                    WHEN b1.south_shared_length < b2.north_shared_length \n",
    "                                    THEN b1.south_shared_length / b2.north_shared_length\n",
    "                                    ELSE b2.north_shared_length / b1.south_shared_length\n",
    "                                END\n",
    "                        }\n",
    "                        // East-West match\n",
    "                        WHEN b1.east_shared_length > 0 AND b2.west_shared_length > 0\n",
    "                            AND b2.x > b1.x AND abs(b2.y - b1.y) < 3\n",
    "                        THEN {\n",
    "                            pair: 'east-west',\n",
    "                            b1_wall: 'east',\n",
    "                            b2_wall: 'west',\n",
    "                            b1_length: b1.east_shared_length,\n",
    "                            b2_length: b2.west_shared_length,\n",
    "                            match_quality: \n",
    "                                CASE \n",
    "                                    WHEN b1.east_shared_length < b2.west_shared_length \n",
    "                                    THEN b1.east_shared_length / b2.west_shared_length\n",
    "                                    ELSE b2.west_shared_length / b1.east_shared_length\n",
    "                                END\n",
    "                        }\n",
    "                        // West-East match\n",
    "                        WHEN b1.west_shared_length > 0 AND b2.east_shared_length > 0\n",
    "                            AND b2.x < b1.x AND abs(b2.y - b1.y) < 3\n",
    "                        THEN {\n",
    "                            pair: 'west-east',\n",
    "                            b1_wall: 'west',\n",
    "                            b2_wall: 'east',\n",
    "                            b1_length: b1.west_shared_length,\n",
    "                            b2_length: b2.east_shared_length,\n",
    "                            match_quality: \n",
    "                                CASE \n",
    "                                    WHEN b1.west_shared_length < b2.east_shared_length \n",
    "                                    THEN b1.west_shared_length / b2.east_shared_length\n",
    "                                    ELSE b2.east_shared_length / b1.west_shared_length\n",
    "                                END\n",
    "                        }\n",
    "                        ELSE null\n",
    "                    END as wall_match\n",
    "                \n",
    "                WHERE wall_match IS NOT NULL\n",
    "                AND wall_match.match_quality > 0.5  // Walls must be similar length\n",
    "                \n",
    "                // Create bidirectional relationships\n",
    "                CREATE (b1)-[r1:ADJACENT_TO {\n",
    "                    wall_pair: wall_match.pair,\n",
    "                    my_wall: wall_match.b1_wall,\n",
    "                    their_wall: wall_match.b2_wall,\n",
    "                    my_shared_length: wall_match.b1_length,\n",
    "                    their_shared_length: wall_match.b2_length,\n",
    "                    match_quality: wall_match.match_quality,\n",
    "                    distance_m: distance,\n",
    "                    adjacency_strength: (wall_match.b1_length + wall_match.b2_length) / 2,\n",
    "                    \n",
    "                    // Energy implications\n",
    "                    thermal_coupling: true,\n",
    "                    cable_distance: distance * 0.5,\n",
    "                    transmission_loss_factor: 0.02 * distance,\n",
    "                    energy_sharing_viable: distance < 3,\n",
    "                    \n",
    "                    // Complementarity based on function\n",
    "                    function_diversity: CASE \n",
    "                        WHEN b1.building_function <> b2.building_function THEN 2.0\n",
    "                        WHEN b1.residential_type <> b2.residential_type THEN 1.5\n",
    "                        ELSE 1.0\n",
    "                    END,\n",
    "                    \n",
    "                    // Solar diversity\n",
    "                    solar_diversity: CASE\n",
    "                        WHEN b1.has_solar <> b2.has_solar THEN 2.0\n",
    "                        WHEN b1.solar_potential <> b2.solar_potential THEN 1.5\n",
    "                        ELSE 1.0\n",
    "                    END,\n",
    "                    \n",
    "                    created_at: datetime()\n",
    "                }]->(b2)\n",
    "                \n",
    "                CREATE (b2)-[r2:ADJACENT_TO {\n",
    "                    wall_pair: wall_match.b2_wall + '-' + wall_match.b1_wall,\n",
    "                    my_wall: wall_match.b2_wall,\n",
    "                    their_wall: wall_match.b1_wall,\n",
    "                    my_shared_length: wall_match.b2_length,\n",
    "                    their_shared_length: wall_match.b1_length,\n",
    "                    match_quality: wall_match.match_quality,\n",
    "                    distance_m: distance,\n",
    "                    adjacency_strength: (wall_match.b1_length + wall_match.b2_length) / 2,\n",
    "                    \n",
    "                    // Same energy implications\n",
    "                    thermal_coupling: true,\n",
    "                    cable_distance: distance * 0.5,\n",
    "                    transmission_loss_factor: 0.02 * distance,\n",
    "                    energy_sharing_viable: distance < 3,\n",
    "                    \n",
    "                    function_diversity: CASE \n",
    "                        WHEN b1.building_function <> b2.building_function THEN 2.0\n",
    "                        WHEN b1.residential_type <> b2.residential_type THEN 1.5\n",
    "                        ELSE 1.0\n",
    "                    END,\n",
    "                    \n",
    "                    solar_diversity: CASE\n",
    "                        WHEN b1.has_solar <> b2.has_solar THEN 2.0\n",
    "                        WHEN b1.solar_potential <> b2.solar_potential THEN 1.5\n",
    "                        ELSE 1.0\n",
    "                    END,\n",
    "                    \n",
    "                    created_at: datetime()\n",
    "                }]->(b1)\n",
    "                \n",
    "                RETURN count(DISTINCT r1) as relationships_created\n",
    "            \"\"\")\n",
    "            \n",
    "            single_result = result.single()\n",
    "            count = single_result['relationships_created'] if single_result else 0\n",
    "            self.stats['relationships_created'] = count * 2  # Both directions\n",
    "            logger.info(f\"Created {count * 2} adjacency relationships ({count} pairs)\")\n",
    "            \n",
    "            return count * 2\n",
    "    \n",
    "    def validate_adjacencies(self) -> Dict:\n",
    "        \"\"\"Validate adjacency patterns match expectations based on housing types\"\"\"\n",
    "        logger.info(\"Validating adjacency patterns...\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            validations = {}\n",
    "            \n",
    "            # Validation 1: Row houses (rijtjeswoning) should have 2 neighbors\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                WHERE b.woningtype = 'rijtjeswoning'\n",
    "                OPTIONAL MATCH (b)-[r:ADJACENT_TO]-()\n",
    "                WITH b, count(DISTINCT r) as neighbor_count\n",
    "                RETURN \n",
    "                    count(b) as total,\n",
    "                    sum(CASE WHEN neighbor_count = 2 THEN 1 ELSE 0 END) as correct,\n",
    "                    avg(neighbor_count) as avg_neighbors\n",
    "            \"\"\")\n",
    "            row = result.single()\n",
    "            if row and row['total'] > 0:\n",
    "                validations['row_houses'] = {\n",
    "                    'total': row['total'],\n",
    "                    'correct': row['correct'] or 0,\n",
    "                    'avg_neighbors': row['avg_neighbors'] or 0,\n",
    "                    'accuracy': (row['correct'] or 0) / row['total']\n",
    "                }\n",
    "            \n",
    "            # Validation 2: Detached (vrijstaand) should have 0 neighbors\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                WHERE b.woningtype = 'vrijstaand'\n",
    "                OPTIONAL MATCH (b)-[r:ADJACENT_TO]-()\n",
    "                WITH b, count(DISTINCT r) as neighbor_count\n",
    "                RETURN \n",
    "                    count(b) as total,\n",
    "                    sum(CASE WHEN neighbor_count = 0 THEN 1 ELSE 0 END) as correct,\n",
    "                    avg(neighbor_count) as avg_neighbors\n",
    "            \"\"\")\n",
    "            row = result.single()\n",
    "            if row and row['total'] > 0:\n",
    "                validations['detached'] = {\n",
    "                    'total': row['total'],\n",
    "                    'correct': row['correct'] or 0,\n",
    "                    'avg_neighbors': row['avg_neighbors'] or 0,\n",
    "                    'accuracy': (row['correct'] or 0) / row['total']\n",
    "                }\n",
    "            \n",
    "            # Validation 3: Semi-detached (twee_onder_1_kap) should have 1 neighbor\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                WHERE b.woningtype = 'twee_onder_1_kap'\n",
    "                OPTIONAL MATCH (b)-[r:ADJACENT_TO]-()\n",
    "                WITH b, count(DISTINCT r) as neighbor_count\n",
    "                RETURN \n",
    "                    count(b) as total,\n",
    "                    sum(CASE WHEN neighbor_count = 1 THEN 1 ELSE 0 END) as correct,\n",
    "                    avg(neighbor_count) as avg_neighbors\n",
    "            \"\"\")\n",
    "            row = result.single()\n",
    "            if row and row['total'] > 0:\n",
    "                validations['semi_detached'] = {\n",
    "                    'total': row['total'],\n",
    "                    'correct': row['correct'] or 0,\n",
    "                    'avg_neighbors': row['avg_neighbors'] or 0,\n",
    "                    'accuracy': (row['correct'] or 0) / row['total']\n",
    "                }\n",
    "            \n",
    "            # Validation 4: MIDDLE_ROW adjacency type should match\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building {adjacency_type: 'MIDDLE_ROW'})\n",
    "                OPTIONAL MATCH (b)-[r:ADJACENT_TO]-()\n",
    "                WITH b, count(DISTINCT r) as neighbor_count\n",
    "                RETURN \n",
    "                    count(b) as total,\n",
    "                    sum(CASE WHEN neighbor_count = 2 THEN 1 ELSE 0 END) as correct,\n",
    "                    avg(neighbor_count) as avg_neighbors\n",
    "            \"\"\")\n",
    "            row = result.single()\n",
    "            if row and row['total'] > 0:\n",
    "                validations['middle_row_type'] = {\n",
    "                    'total': row['total'],\n",
    "                    'correct': row['correct'] or 0,\n",
    "                    'avg_neighbors': row['avg_neighbors'] or 0,\n",
    "                    'accuracy': (row['correct'] or 0) / row['total']\n",
    "                }\n",
    "            \n",
    "            # Validation 5: Reciprocal relationships\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b1:Building)-[r:ADJACENT_TO]->(b2:Building)\n",
    "                WHERE b1.ogc_fid < b2.ogc_fid\n",
    "                OPTIONAL MATCH (b2)-[r2:ADJACENT_TO]->(b1)\n",
    "                RETURN \n",
    "                    count(r) as total_relationships,\n",
    "                    count(r2) as reciprocal_relationships\n",
    "            \"\"\")\n",
    "            row = result.single()\n",
    "            if row and row['total_relationships'] > 0:\n",
    "                validations['reciprocal'] = {\n",
    "                    'total': row['total_relationships'],\n",
    "                    'reciprocal': row['reciprocal_relationships'] or 0,\n",
    "                    'accuracy': (row['reciprocal_relationships'] or 0) / row['total_relationships']\n",
    "                }\n",
    "            \n",
    "            self.stats['validation_results'] = validations\n",
    "            return validations\n",
    "    \n",
    "    def create_adjacency_clusters(self):\n",
    "        \"\"\"Create natural clusters from adjacency patterns\"\"\"\n",
    "        logger.info(\"Creating natural adjacency clusters...\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Clear existing adjacency clusters\n",
    "            session.run(\"MATCH (ac:AdjacencyCluster) DETACH DELETE ac\")\n",
    "            \n",
    "            total_clusters = 0\n",
    "            \n",
    "            # Method 1: Row House Clusters - FIXED to use elementId()\n",
    "            logger.info(\"Creating row house clusters...\")\n",
    "            \n",
    "            result = session.run(\"\"\"\n",
    "                // Find unprocessed row houses\n",
    "                MATCH (start:Building)\n",
    "                WHERE (start.adjacency_type = 'MIDDLE_ROW' OR start.adjacency_type = 'END_ROW')\n",
    "                AND NOT EXISTS((start)<-[:IN_ADJACENCY_CLUSTER]-())\n",
    "                \n",
    "                // Find connected row of buildings\n",
    "                MATCH path = (start)-[:ADJACENT_TO*1..20]-(connected:Building)\n",
    "                WHERE connected.adjacency_type IN ['MIDDLE_ROW', 'END_ROW', 'CORNER']\n",
    "                \n",
    "                WITH start, collect(DISTINCT connected) + [start] as row_buildings\n",
    "                WHERE size(row_buildings) >= 3\n",
    "                \n",
    "                // Get LV group for cluster\n",
    "                WITH row_buildings, row_buildings[0].lv_group_id as lv_group,\n",
    "                    row_buildings[0].district_name as district,\n",
    "                    row_buildings[0].ogc_fid as first_building_id\n",
    "                \n",
    "                CREATE (ac:AdjacencyCluster {\n",
    "                    cluster_id: 'ROW_' + lv_group + '_' + toString(first_building_id),\n",
    "                    cluster_type: 'ROW_HOUSES',\n",
    "                    member_count: size(row_buildings),\n",
    "                    lv_group_id: lv_group,\n",
    "                    district_name: district,\n",
    "                    created_at: datetime(),\n",
    "                    pattern: 'LINEAR',\n",
    "                    thermal_benefit: 'HIGH',\n",
    "                    cable_savings: 'HIGH',\n",
    "                    avg_shared_walls: 2.0\n",
    "                })\n",
    "                \n",
    "                WITH ac, row_buildings\n",
    "                UNWIND row_buildings as building\n",
    "                CREATE (building)-[:IN_ADJACENCY_CLUSTER {\n",
    "                    joined_at: datetime()\n",
    "                }]->(ac)\n",
    "                \n",
    "                RETURN count(DISTINCT ac) as clusters_created\n",
    "            \"\"\")\n",
    "            \n",
    "            row_result = result.single()\n",
    "            row_count = row_result['clusters_created'] if row_result else 0\n",
    "            logger.info(f\"Created {row_count} row house clusters\")\n",
    "            \n",
    "            # Method 2: Corner/Courtyard Clusters\n",
    "            logger.info(\"Creating corner/courtyard clusters...\")\n",
    "            \n",
    "            result = session.run(\"\"\"\n",
    "                // Find unprocessed corner/courtyard buildings\n",
    "                MATCH (center:Building)\n",
    "                WHERE center.adjacency_type IN ['CORNER', 'COURTYARD']\n",
    "                AND NOT EXISTS((center)<-[:IN_ADJACENCY_CLUSTER]-())\n",
    "                \n",
    "                // Find immediate neighbors\n",
    "                MATCH (center)-[:ADJACENT_TO]-(neighbor:Building)\n",
    "                WHERE NOT EXISTS((neighbor)<-[:IN_ADJACENCY_CLUSTER]-())\n",
    "                \n",
    "                WITH center, collect(DISTINCT neighbor) as neighbors\n",
    "                WHERE size(neighbors) >= 2\n",
    "                \n",
    "                CREATE (ac:AdjacencyCluster {\n",
    "                    cluster_id: 'CORNER_' + center.lv_group_id + '_' + toString(center.ogc_fid),\n",
    "                    cluster_type: CASE \n",
    "                        WHEN center.adjacency_type = 'COURTYARD' THEN 'COURTYARD_BLOCK'\n",
    "                        ELSE 'CORNER_BLOCK'\n",
    "                    END,\n",
    "                    member_count: size(neighbors) + 1,\n",
    "                    lv_group_id: center.lv_group_id,\n",
    "                    district_name: center.district_name,\n",
    "                    created_at: datetime(),\n",
    "                    pattern: CASE \n",
    "                        WHEN center.adjacency_type = 'COURTYARD' THEN 'ENCLOSED'\n",
    "                        ELSE 'L_SHAPE'\n",
    "                    END,\n",
    "                    thermal_benefit: 'MEDIUM',\n",
    "                    cable_savings: 'MEDIUM',\n",
    "                    avg_shared_walls: 1.5\n",
    "                })\n",
    "                \n",
    "                CREATE (center)-[:IN_ADJACENCY_CLUSTER {\n",
    "                    role: 'CENTER',\n",
    "                    joined_at: datetime()\n",
    "                }]->(ac)\n",
    "                \n",
    "                WITH ac, neighbors\n",
    "                UNWIND neighbors as neighbor\n",
    "                CREATE (neighbor)-[:IN_ADJACENCY_CLUSTER {\n",
    "                    role: 'MEMBER',\n",
    "                    joined_at: datetime()\n",
    "                }]->(ac)\n",
    "                \n",
    "                RETURN count(DISTINCT ac) as created\n",
    "            \"\"\")\n",
    "            \n",
    "            corner_result = result.single()\n",
    "            corner_count = corner_result['created'] if corner_result else 0\n",
    "            logger.info(f\"Created {corner_count} corner/courtyard clusters\")\n",
    "            \n",
    "            # Method 3: Apartment Complex Clusters - FIXED to use ogc_fid\n",
    "            logger.info(\"Creating apartment clusters...\")\n",
    "            \n",
    "            result = session.run(\"\"\"\n",
    "                // Find apartment buildings in same LV group and location\n",
    "                MATCH (b1:Building)\n",
    "                WHERE b1.woningtype = 'appartement'\n",
    "                AND NOT EXISTS((b1)<-[:IN_ADJACENCY_CLUSTER]-())\n",
    "                \n",
    "                MATCH (b2:Building)\n",
    "                WHERE b2.woningtype = 'appartement'\n",
    "                AND b1.ogc_fid < b2.ogc_fid\n",
    "                AND b1.lv_group_id = b2.lv_group_id\n",
    "                AND b1.district_name = b2.district_name\n",
    "                AND NOT EXISTS((b2)<-[:IN_ADJACENCY_CLUSTER]-())\n",
    "                AND sqrt((b2.x - b1.x)^2 + (b2.y - b1.y)^2) < 50  // Within 50m\n",
    "                \n",
    "                WITH b1.lv_group_id as lv_group, \n",
    "                    b1.district_name as district,\n",
    "                    collect(DISTINCT b1) + collect(DISTINCT b2) as apartments,\n",
    "                    min(b1.ogc_fid) as min_building_id\n",
    "                WHERE size(apartments) >= 2\n",
    "                \n",
    "                CREATE (ac:AdjacencyCluster {\n",
    "                    cluster_id: 'APT_' + lv_group + '_' + toString(min_building_id),\n",
    "                    cluster_type: 'APARTMENT_COMPLEX',\n",
    "                    member_count: size(apartments),\n",
    "                    lv_group_id: lv_group,\n",
    "                    district_name: district,\n",
    "                    created_at: datetime(),\n",
    "                    pattern: 'VERTICAL',\n",
    "                    thermal_benefit: 'LOW',\n",
    "                    cable_savings: 'VERY_HIGH',\n",
    "                    avg_shared_walls: 1.0\n",
    "                })\n",
    "                \n",
    "                WITH ac, apartments\n",
    "                UNWIND apartments as apt\n",
    "                CREATE (apt)-[:IN_ADJACENCY_CLUSTER {\n",
    "                    joined_at: datetime()\n",
    "                }]->(ac)\n",
    "                \n",
    "                RETURN count(DISTINCT ac) as created\n",
    "            \"\"\")\n",
    "            \n",
    "            apt_result = result.single()\n",
    "            apt_count = apt_result['created'] if apt_result else 0\n",
    "            logger.info(f\"Created {apt_count} apartment clusters\")\n",
    "            \n",
    "            total_clusters = row_count + corner_count + apt_count\n",
    "            self.stats['clusters_created'] = total_clusters\n",
    "            \n",
    "            logger.info(f\"Created {total_clusters} adjacency clusters total\")\n",
    "            \n",
    "            return total_clusters\n",
    "    \n",
    "    def enhance_building_metrics(self):\n",
    "        \"\"\"Add adjacency-based metrics to buildings\"\"\"\n",
    "        logger.info(\"Enhancing building metrics with adjacency data...\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Add adjacency counts and metrics\n",
    "            session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                OPTIONAL MATCH (b)-[adj:ADJACENT_TO]-()\n",
    "                WITH b, \n",
    "                     count(DISTINCT adj) as adjacency_count,\n",
    "                     avg(adj.adjacency_strength) as avg_strength,\n",
    "                     max(adj.complementarity_potential) as max_complementarity,\n",
    "                     collect(DISTINCT adj.wall_pair) as shared_walls\n",
    "                \n",
    "                SET b.adjacency_count = adjacency_count,\n",
    "                    b.avg_adjacency_strength = COALESCE(avg_strength, 0),\n",
    "                    b.max_complementarity = COALESCE(max_complementarity, 0),\n",
    "                    b.has_adjacent_neighbors = adjacency_count > 0,\n",
    "                    b.shared_wall_directions = shared_walls,\n",
    "                    b.isolation_factor = CASE \n",
    "                        WHEN adjacency_count = 0 THEN 1.0\n",
    "                        WHEN adjacency_count = 1 THEN 0.7\n",
    "                        WHEN adjacency_count = 2 THEN 0.5\n",
    "                        ELSE 0.3\n",
    "                    END,\n",
    "                    b.thermal_efficiency_boost = 1.0 + (adjacency_count * 0.15)\n",
    "            \"\"\")\n",
    "            \n",
    "            # Add complementarity potential for adjacent pairs\n",
    "            session.run(\"\"\"\n",
    "                MATCH (b1:Building)-[adj:ADJACENT_TO]-(b2:Building)\n",
    "                WHERE b1.ogc_fid < b2.ogc_fid\n",
    "                \n",
    "                WITH b1, b2, adj,\n",
    "                     adj.function_diversity * adj.solar_diversity * adj.match_quality as potential\n",
    "                \n",
    "                SET adj.complementarity_potential = potential,\n",
    "                    adj.priority_for_sharing = CASE\n",
    "                        WHEN potential > 2.5 THEN 'VERY_HIGH'\n",
    "                        WHEN potential > 2.0 THEN 'HIGH'\n",
    "                        WHEN potential > 1.5 THEN 'MEDIUM'\n",
    "                        ELSE 'LOW'\n",
    "                    END,\n",
    "                    adj.thermal_resistance_reduction = 0.1 * adj.match_quality\n",
    "            \"\"\")\n",
    "            \n",
    "            # Update cluster metrics\n",
    "            session.run(\"\"\"\n",
    "                MATCH (ac:AdjacencyCluster)<-[:IN_ADJACENCY_CLUSTER]-(b:Building)\n",
    "                WITH ac, \n",
    "                     collect(b) as members,\n",
    "                     avg(b.solar_capacity_kwp) as avg_solar_potential,\n",
    "                     sum(CASE WHEN b.has_solar THEN 1 ELSE 0 END) as solar_count,\n",
    "                     sum(CASE WHEN b.has_battery THEN 1 ELSE 0 END) as battery_count,\n",
    "                     sum(CASE WHEN b.has_heat_pump THEN 1 ELSE 0 END) as hp_count,\n",
    "                     collect(DISTINCT b.building_function) as functions\n",
    "                     \n",
    "                SET ac.avg_solar_potential_kwp = avg_solar_potential,\n",
    "                    ac.solar_penetration = toFloat(solar_count) / size(members),\n",
    "                    ac.battery_penetration = toFloat(battery_count) / size(members),\n",
    "                    ac.hp_penetration = toFloat(hp_count) / size(members),\n",
    "                    ac.function_diversity = size(functions),\n",
    "                    ac.energy_sharing_potential = CASE\n",
    "                        WHEN size(functions) > 1 AND solar_count > 0 THEN 'HIGH'\n",
    "                        WHEN solar_count > 0 OR battery_count > 0 THEN 'MEDIUM'\n",
    "                        ELSE 'LOW'\n",
    "                    END\n",
    "            \"\"\")\n",
    "            \n",
    "            logger.info(\"Building metrics enhanced with adjacency data\")\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate comprehensive adjacency report\"\"\"\n",
    "        logger.info(\"\\n\" + \"=\"*60)\n",
    "        logger.info(\"ADJACENCY UPDATE REPORT\")\n",
    "        logger.info(\"=\"*60)\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # Overall statistics\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                RETURN \n",
    "                    count(b) as total_buildings,\n",
    "                    sum(CASE WHEN b.num_shared_walls > 0 THEN 1 ELSE 0 END) as with_shared_walls,\n",
    "                    sum(CASE WHEN b.adjacency_count > 0 THEN 1 ELSE 0 END) as with_adjacencies,\n",
    "                    avg(b.adjacency_count) as avg_adjacencies\n",
    "            \"\"\")\n",
    "            stats = result.single()\n",
    "            \n",
    "            if stats:\n",
    "                print(f\"\\nBuilding Statistics:\")\n",
    "                print(f\"  Total buildings: {stats['total_buildings']}\")\n",
    "                print(f\"  With shared walls: {stats['with_shared_walls']}\")\n",
    "                print(f\"  With adjacencies found: {stats['with_adjacencies']}\")\n",
    "                if stats['avg_adjacencies']:\n",
    "                    print(f\"  Average adjacencies: {stats['avg_adjacencies']:.2f}\")\n",
    "            \n",
    "            # Adjacency type distribution\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                WHERE b.adjacency_type IS NOT NULL\n",
    "                RETURN b.adjacency_type as type, count(b) as count\n",
    "                ORDER BY count DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            print(f\"\\nAdjacency Type Distribution:\")\n",
    "            for record in result:\n",
    "                print(f\"  {record['type']}: {record['count']}\")\n",
    "            \n",
    "            # Housing type analysis - FIXED\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)\n",
    "                WHERE b.woningtype IS NOT NULL\n",
    "                OPTIONAL MATCH (b)-[adj:ADJACENT_TO]-()\n",
    "                WITH b, b.woningtype as housing_type, count(adj) as adjacency_count\n",
    "                WITH housing_type, \n",
    "                    count(DISTINCT b) as count,\n",
    "                    avg(adjacency_count) as avg_adjacencies\n",
    "                RETURN housing_type, count, avg_adjacencies\n",
    "                ORDER BY count DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            print(f\"\\nHousing Type Adjacency Analysis:\")\n",
    "            for record in result:\n",
    "                if record['avg_adjacencies'] is not None:\n",
    "                    print(f\"  {record['housing_type']}: {record['count']} buildings, \"\n",
    "                        f\"avg {record['avg_adjacencies']:.1f} adjacencies\")\n",
    "                else:\n",
    "                    print(f\"  {record['housing_type']}: {record['count']} buildings, no adjacencies\")\n",
    "            \n",
    "            # Relationship statistics\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH ()-[adj:ADJACENT_TO]->()\n",
    "                RETURN \n",
    "                    count(adj)/2 as total_relationships,\n",
    "                    avg(adj.distance_m) as avg_distance,\n",
    "                    avg(adj.adjacency_strength) as avg_strength,\n",
    "                    avg(adj.match_quality) as avg_match_quality,\n",
    "                    avg(adj.complementarity_potential) as avg_potential\n",
    "            \"\"\")\n",
    "            rel_stats = result.single()\n",
    "            \n",
    "            print(f\"\\nAdjacency Relationships:\")\n",
    "            if rel_stats and rel_stats['total_relationships']:\n",
    "                print(f\"  Total pairs: {rel_stats['total_relationships']}\")\n",
    "                if rel_stats['avg_distance']:\n",
    "                    print(f\"  Avg distance: {rel_stats['avg_distance']:.2f} m\")\n",
    "                if rel_stats['avg_strength']:\n",
    "                    print(f\"  Avg strength: {rel_stats['avg_strength']:.2f}\")\n",
    "                if rel_stats['avg_match_quality']:\n",
    "                    print(f\"  Avg match quality: {rel_stats['avg_match_quality']:.2f}\")\n",
    "                if rel_stats['avg_potential']:\n",
    "                    print(f\"  Avg complementarity: {rel_stats['avg_potential']:.2f}\")\n",
    "            \n",
    "            # Cluster statistics\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (ac:AdjacencyCluster)\n",
    "                RETURN \n",
    "                    ac.cluster_type as type,\n",
    "                    count(ac) as count,\n",
    "                    avg(ac.member_count) as avg_size,\n",
    "                    avg(ac.solar_penetration) as avg_solar_pen\n",
    "                ORDER BY count DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            print(f\"\\nAdjacency Clusters:\")\n",
    "            has_clusters = False\n",
    "            for record in result:\n",
    "                has_clusters = True\n",
    "                solar_pen_str = f\"{record['avg_solar_pen']:.1%}\" if record['avg_solar_pen'] is not None else \"N/A\"\n",
    "                print(f\"  {record['type']}: {record['count']} clusters, \"\n",
    "                    f\"avg size: {record['avg_size']:.1f}, \"\n",
    "                    f\"solar pen: {solar_pen_str}\")\n",
    "            if not has_clusters:\n",
    "                print(\"  No clusters created\")\n",
    "            \n",
    "            # LV Group adjacency summary\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b:Building)-[:ADJACENT_TO]-()\n",
    "                WITH b.lv_group_id as lv_group, count(DISTINCT b) as adjacent_buildings\n",
    "                MATCH (b2:Building {lv_group_id: lv_group})\n",
    "                WITH lv_group, \n",
    "                    adjacent_buildings,\n",
    "                    count(DISTINCT b2) as total_buildings\n",
    "                RETURN lv_group,\n",
    "                    adjacent_buildings,\n",
    "                    total_buildings,\n",
    "                    toFloat(adjacent_buildings) / total_buildings as adjacency_ratio\n",
    "                ORDER BY adjacency_ratio DESC\n",
    "                LIMIT 10\n",
    "            \"\"\")\n",
    "            \n",
    "            print(f\"\\nTop LV Groups by Adjacency Ratio:\")\n",
    "            for record in result:\n",
    "                print(f\"  {record['lv_group']}: {record['adjacent_buildings']}/{record['total_buildings']} \"\n",
    "                    f\"({record['adjacency_ratio']:.1%})\")\n",
    "            \n",
    "            # Top complementarity pairs\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (b1:Building)-[adj:ADJACENT_TO]-(b2:Building)\n",
    "                WHERE b1.ogc_fid < b2.ogc_fid\n",
    "                AND adj.complementarity_potential > 1.5\n",
    "                RETURN \n",
    "                    b1.ogc_fid as building1,\n",
    "                    b2.ogc_fid as building2,\n",
    "                    b1.building_function as func1,\n",
    "                    b2.building_function as func2,\n",
    "                    b1.woningtype as type1,\n",
    "                    b2.woningtype as type2,\n",
    "                    adj.wall_pair as walls,\n",
    "                    adj.complementarity_potential as potential\n",
    "                ORDER BY potential DESC\n",
    "                LIMIT 5\n",
    "            \"\"\")\n",
    "            \n",
    "            print(f\"\\nTop Complementarity Pairs:\")\n",
    "            has_pairs = False\n",
    "            for record in result:\n",
    "                has_pairs = True\n",
    "                print(f\"  Buildings {record['building1']}-{record['building2']}: \"\n",
    "                    f\"{record['func1']}/{record['func2']}, \"\n",
    "                    f\"{record['type1']}/{record['type2']}, \"\n",
    "                    f\"potential: {record['potential']:.2f}\")\n",
    "            if not has_pairs:\n",
    "                print(\"  No high-complementarity pairs found\")\n",
    "            \n",
    "            # Validation results\n",
    "            if self.stats['validation_results']:\n",
    "                print(f\"\\nValidation Results:\")\n",
    "                for key, val in self.stats['validation_results'].items():\n",
    "                    if key == 'reciprocal':\n",
    "                        print(f\"  {key}: {val.get('reciprocal', 0)}/{val.get('total', 0)} \"\n",
    "                            f\"({val.get('accuracy', 0):.1%} accuracy)\")\n",
    "                    else:\n",
    "                        print(f\"  {key}: {val.get('correct', 0)}/{val.get('total', 0)} \"\n",
    "                            f\"({val.get('accuracy', 0):.1%} accuracy, \"\n",
    "                            f\"avg: {val.get('avg_neighbors', 0):.1f})\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"ADJACENCY UPDATE COMPLETE\")\n",
    "            print(\"=\"*60)\n",
    "    \n",
    "    def run_full_update(self):\n",
    "        \"\"\"Run complete adjacency update process using PostgreSQL data\"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # Check KG status\n",
    "            status = self.check_kg_status()\n",
    "            logger.info(f\"KG Status: {status}\")\n",
    "            \n",
    "            if not status['buildings_exist']:\n",
    "                logger.error(\"No buildings found in KG. Run main KG builder (Part 1) first.\")\n",
    "                return False\n",
    "            \n",
    "            if status['adjacencies_exist']:\n",
    "                logger.warning(\"Adjacencies already exist. They will be recreated.\")\n",
    "            \n",
    "            # Update shared wall data from PostgreSQL\n",
    "            if not status['has_shared_walls']:\n",
    "                logger.info(\"Updating shared wall data from PostgreSQL...\")\n",
    "                self.update_shared_wall_data_from_postgres()\n",
    "            else:\n",
    "                logger.info(\"Shared wall data already exists in Neo4j\")\n",
    "            \n",
    "            # Create adjacency relationships\n",
    "            self.create_adjacency_relationships()\n",
    "            \n",
    "            # Validate\n",
    "            validation = self.validate_adjacencies()\n",
    "            \n",
    "            # Create clusters\n",
    "            self.create_adjacency_clusters()\n",
    "            \n",
    "            # Enhance metrics\n",
    "            self.enhance_building_metrics()\n",
    "            \n",
    "            # Generate report\n",
    "            self.generate_report()\n",
    "            \n",
    "            # Calculate time\n",
    "            elapsed = (datetime.now() - start_time).total_seconds()\n",
    "            logger.info(f\"Total processing time: {elapsed:.2f} seconds\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during adjacency update: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            raise\n",
    "\n",
    "# ============================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration (SAME AS PART 1)\n",
    "    NEO4J_URI = \"bolt://localhost:7687\"\n",
    "    NEO4J_USER = \"neo4j\"\n",
    "    NEO4J_PASSWORD = \"aminasad\"\n",
    "    \n",
    "    # PostgreSQL configuration (SAME AS PART 1)\n",
    "    PG_HOST = \"localhost\"\n",
    "    PG_DATABASE = \"research\"\n",
    "    PG_USER = \"aminj\"\n",
    "    PG_PASSWORD = \"Aminej@geodan!\"\n",
    "    \n",
    "    print(\"Starting Adjacency Module (Part 2) using PostgreSQL data...\")\n",
    "    print(f\"Connecting to PostgreSQL database: {PG_DATABASE}\")\n",
    "    print(f\"Connecting to Neo4j at: {NEO4J_URI}\")\n",
    "    \n",
    "    # Create updater with both connections\n",
    "    updater = AdjacencyUpdater(\n",
    "        NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD,\n",
    "        PG_HOST, PG_DATABASE, PG_USER, PG_PASSWORD\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Run full update using PostgreSQL data\n",
    "        success = updater.run_full_update()\n",
    "        \n",
    "        if success:\n",
    "            print(\"\\n✅ Adjacency update completed successfully!\")\n",
    "            print(\"Your KG now has:\")\n",
    "            print(\"  - ADJACENT_TO relationships with energy implications\")\n",
    "            print(\"  - Natural adjacency clusters (row houses, corners, apartments)\")\n",
    "            print(\"  - Enhanced complementarity potential for adjacent buildings\")\n",
    "            print(\"  - Thermal coupling metrics\")\n",
    "            print(\"  - Validation against housing types (woningtype)\")\n",
    "            print(\"\\nReady for GNN processing with adjacency-aware features!\")\n",
    "        \n",
    "    finally:\n",
    "        updater.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDsaie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
